{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "import shutil\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tree import *\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from utils import Vocab\n",
    "from keras.utils import to_categorical\n",
    "from gensim.models.wrappers import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataPath = \"trainsmall.txt\"\n",
    "trainTreePath = \"trees/train\"\n",
    "testTreePath = \"trees/test\"\n",
    "testDataPath = \"devwithoutlabelssmall.txt\"\n",
    "# Output file that will be generated. This file can be directly submitted.\n",
    "solutionPath = \"test_output.txt\"\n",
    "# Path to directory where GloVe file is saved.\n",
    "### this glove Directory is of Prakhar laptop \n",
    "gloveDir = \"E:\\glove\"\n",
    "#gloveDir = \"/home/bt1/17CS10037/starterkit/glove\"\n",
    "NUM_FOLDS = 5   # Number of classes - Happy, Sad, Angry, Others\n",
    "MAX_SEQUENCE_LENGTH = 100 \n",
    "MAX_NB_WORDS = 20000        # All sentences having lesser number of words than this will be padded\n",
    "EMBEDDING_DIM = 25               # The dimension of the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2emotion = {0:\"others\", 1:\"happy\", 2: \"sad\", 3:\"angry\"}\n",
    "emotion2label = {\"others\":0, \"happy\":1, \"sad\":2, \"angry\":3}\n",
    "def getMetrics(predictions, ground):\n",
    "    \"\"\"Given predicted labels and the respective ground truth labels, display some metrics\n",
    "    Input: shape [# of samples, NUM_CLASSES]\n",
    "        predictions : Model output. Every row has 4 decimal values, with the highest belonging to the predicted class\n",
    "        ground : Ground truth labels, converted to one-hot encodings. A sample belonging to Happy class will be [0, 1, 0, 0]\n",
    "    Output:\n",
    "        accuracy : Average accuracy\n",
    "        microPrecision : Precision calculated on a micro level. Ref - https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin/16001\n",
    "        microRecall : Recall calculated on a micro level\n",
    "        microF1 : Harmonic mean of microPrecision and microRecall. Higher value implies better classification  \n",
    "    \"\"\"\n",
    "    # [0.1, 0.3 , 0.2, 0.1] -> [0, 1, 0, 0]\n",
    "    discretePredictions = to_categorical(predictions.argmax(axis=1))\n",
    "    \n",
    "    truePositives = np.sum(discretePredictions*ground, axis=0)\n",
    "    falsePositives = np.sum(np.clip(discretePredictions - ground, 0, 1), axis=0)\n",
    "    falseNegatives = np.sum(np.clip(ground-discretePredictions, 0, 1), axis=0)\n",
    "    '''\n",
    "    ##########################################################\n",
    "    ##########################################################\n",
    "    \n",
    "    IMPORTANT\n",
    "    Please add  code here or somewhere else to print the TruePositives,FalsePositives,FalseNegatives\n",
    "    \n",
    "    ##########################################################\n",
    "    ##########################################################\n",
    "    '''\n",
    "    \n",
    "    print(\"True Positives per class : \", truePositives)\n",
    "    print(\"False Positives per class : \", falsePositives)\n",
    "    print(\"False Negatives per class : \", falseNegatives)\n",
    "    \n",
    "    # ------------- Macro level calculation ---------------\n",
    "    macroPrecision = 0\n",
    "    macroRecall = 0\n",
    "    # We ignore the \"Others\" class during the calculation of Precision, Recall and F1\n",
    "    for c in range(1, NUM_CLASSES):\n",
    "        precision = truePositives[c] / (truePositives[c] + falsePositives[c])\n",
    "        macroPrecision += precision\n",
    "        recall = truePositives[c] / (truePositives[c] + falseNegatives[c])\n",
    "        macroRecall += recall\n",
    "        f1 = ( 2 * recall * precision ) / (precision + recall) if (precision+recall) > 0 else 0\n",
    "        print(\"Class %s : Precision : %.3f, Recall : %.3f, F1 : %.3f\" % (label2emotion[c], precision, recall, f1))\n",
    "    \n",
    "    macroPrecision /= 3\n",
    "    macroRecall /= 3\n",
    "    macroF1 = (2 * macroRecall * macroPrecision ) / (macroPrecision + macroRecall) if (macroPrecision+macroRecall) > 0 else 0\n",
    "    print(\"Ignoring the Others class, Macro Precision : %.4f, Macro Recall : %.4f, Macro F1 : %.4f\" % (macroPrecision, macroRecall, macroF1))   \n",
    "    \n",
    "    # ------------- Micro level calculation ---------------\n",
    "    truePositives = truePositives[1:].sum()\n",
    "    falsePositives = falsePositives[1:].sum()\n",
    "    falseNegatives = falseNegatives[1:].sum()    \n",
    "    \n",
    "    print(\"Ignoring the Others class, Micro TP : %d, FP : %d, FN : %d\" % (truePositives, falsePositives, falseNegatives))\n",
    "    \n",
    "    microPrecision = truePositives / (truePositives + falsePositives)\n",
    "    microRecall = truePositives / (truePositives + falseNegatives)\n",
    "    \n",
    "    microF1 = ( 2 * microRecall * microPrecision ) / (microPrecision + microRecall) if (microPrecision+microRecall) > 0 else 0\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    ground = ground.argmax(axis=1)\n",
    "    accuracy = np.mean(predictions==ground)\n",
    "    \n",
    "    print(\"Accuracy : %.4f, Micro Precision : %.4f, Micro Recall : %.4f, Micro F1 : %.4f\" % (accuracy, microPrecision, microRecall, microF1))\n",
    "    return accuracy, microPrecision, microRecall, microF1\n",
    "\n",
    "def writeNormalisedData(dataFilePath, texts):\n",
    "    \"\"\"Write normalised data to a file\n",
    "    Input:\n",
    "        dataFilePath : Path to original train/test file that has been processed\n",
    "        texts : List containing the normalised 3 turn conversations, separated by the <eos> tag.\n",
    "    \"\"\"\n",
    "    \n",
    "    '''\n",
    "    ##########################################################\n",
    "    ##########################################################\n",
    "    \n",
    "    You May ignore this function\n",
    "    \n",
    "    ##########################################################\n",
    "    ##########################################################\n",
    "    '''\n",
    "    normalisedDataFilePath = dataFilePath.replace(\".txt\", \"_normalised.txt\")\n",
    "    with io.open(normalisedDataFilePath, 'w', encoding='utf8') as fout:\n",
    "        with io.open(dataFilePath, encoding='utf8') as fin:\n",
    "            fin.readline()\n",
    "            for lineNum, line in enumerate(fin):\n",
    "                line = line.strip().split('\\t')\n",
    "                normalisedLine = texts[lineNum].strip().split('<eos>')\n",
    "                fout.write(line[0] + '\\t')\n",
    "                # Write the original turn, followed by the normalised version of the same turn\n",
    "                fout.write(line[1] + '\\t' + normalisedLine[0] + '\\t')\n",
    "                fout.write(line[2] + '\\t' + normalisedLine[1] + '\\t')\n",
    "                fout.write(line[3] + '\\t' + normalisedLine[2] + '\\t')\n",
    "                try:\n",
    "                    # If label information available (train time)\n",
    "                    fout.write(line[4] + '\\n')    \n",
    "                except:\n",
    "                    # If label information not available (test time)\n",
    "                    fout.write('\\n')\n",
    "\n",
    "def getEmbeddingMatrix(wordIndex):\n",
    "    \"\"\"Populate an embedding matrix using a word-index. If the word \"happy\" has an index 19,\n",
    "       the 19th row in the embedding matrix should contain the embedding vector for the word \"happy\".\n",
    "    Input:\n",
    "        wordIndex : A dictionary of (word : index) pairs, extracted using a tokeniser\n",
    "    Output:\n",
    "        embeddingMatrix : A matrix where every row has 100 dimensional GloVe embedding\n",
    "    \"\"\"\n",
    "    embeddingsIndex = {}\n",
    "    # Load the embedding vectors from ther GloVe file\n",
    "    with io.open(os.path.join(gloveDir, 'glove.6B.300d.txt'), encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            embeddingVector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddingsIndex[word] = embeddingVector\n",
    "    \n",
    "    print('Found %s word vectors.' % len(embeddingsIndex))\n",
    "    \n",
    "    # Minimum word index of any word is 1. \n",
    "    embeddingMatrix = np.zeros((len(wordIndex) + 1, EMBEDDING_DIM))\n",
    "    for word, i in wordIndex.items():\n",
    "        embeddingVector = embeddingsIndex.get(word)\n",
    "        if embeddingVector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embeddingMatrix[i] = embeddingVector\n",
    "    \n",
    "    return embeddingMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['😍', '😍']\n",
      "  :see-no-evil_monkey:  me así, se  :relieved_face:  ds  :two_hearts:  :two_women_holding_hands:  :bikini:  hello  :woman:  :graduation_cap:  emoji hello  how are  :smiling_face_with_smiling_eyes:  you today\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import regex\n",
    "\n",
    "def split_count(text):\n",
    "\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X', text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "\n",
    "    return emoji_list\n",
    "\n",
    "line1 = [\"🤔 🙈 me así, se 😌 ds 💕👭👙 hello 👩🎓 emoji hello  how are 😊 you today🙅🏽🙅🏽\"]\n",
    "line=[\"money money and lots of money😍😍\"]\n",
    "\n",
    "counter = split_count(line[0])\n",
    "print(counter)\n",
    "emojis = split_count(line1[0])\n",
    "for c in emojis:\n",
    "    lineSplit = line1[0].split(c)\n",
    "    while True:\n",
    "        try:\n",
    "            lineSplit.remove('')\n",
    "        except:\n",
    "            break\n",
    "    cSpace = ' ' + emoji.UNICODE_EMOJI[c] + ' '    \n",
    "    line1[0] = cSpace.join(lineSplit)\n",
    "print(line1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(user_string):\n",
    "    user_string = user_string.split(\" \")\n",
    "    j = 0\n",
    "    for _str in user_string:\n",
    "        # File path which consists of Abbreviations.\n",
    "        fileName = \"slang.txt\"\n",
    "        # File Access mode [Read Mode]\n",
    "        accessMode = \"r\"\n",
    "        with open(fileName, accessMode) as myCSVfile:\n",
    "            # Reading file as CSV with delimiter as \"=\", so that abbreviation are stored in row[0] and phrases in row[1]\n",
    "            dataFromFile = csv.reader(myCSVfile, delimiter=\"=\")\n",
    "            # Removing Special Characters.\n",
    "            _str = re.sub('[^a-zA-Z0-9-_.]', '', _str)\n",
    "            for row in dataFromFile:\n",
    "                # Check if selected word matches short forms[LHS] in text file.\n",
    "                if _str.upper() == row[0]:\n",
    "                    # If match found replace it with its appropriate phrase in text file.\n",
    "                    user_string[j] = row[1]\n",
    "            myCSVfile.close()\n",
    "        j = j + 1\n",
    "    # Replacing commas with spaces for final output.\n",
    "    a = ' '.join(user_string)\n",
    "    print('')\n",
    "    str = j\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(dataFilePath, mode, generator):\n",
    "    \"\"\"Load data from a file, process and return indices, conversations and labels in separate lists\n",
    "    Input:\n",
    "        dataFilePath : Path to train/test file to be processed\n",
    "        mode : \"train\" mode returns labels. \"test\" mode doesn't return labels.\n",
    "    Output:\n",
    "        indices : Unique conversation ID list\n",
    "        conversations : List of 3 turn conversations, processed and each turn separated by the <eos> tag\n",
    "        labels : [Only available in \"train\" mode] List of labels\n",
    "    \"\"\"\n",
    "    \n",
    "    '''\n",
    "    ##########################################################\n",
    "    ##########################################################\n",
    "    \n",
    "    IMPORTANT\n",
    "    Please try to better the pre-processing here by sepearting the emojis with text like  \"hmm😞\", \"now‼‼‼😣😤😤\" & etc.\n",
    "    Also look for other methods.\n",
    "    \n",
    "    ##########################################################\n",
    "    ##########################################################\n",
    "    '''\n",
    "    indices = []\n",
    "    conversations = []\n",
    "    trees = []\n",
    "    labels = []\n",
    "    i=0\n",
    "\n",
    "    if generator :\n",
    "        if mode=='train':\n",
    "            open(\"train_trees.ptb\", \"w\").close()\n",
    "        else:\n",
    "            open(\"test_trees.ptb\", \"w\").close()\n",
    "\n",
    "        with open('../../stanford-corenlp-full-2018-10-05/output.txt','w') as f:\n",
    "            f.write(\"\")\n",
    "\n",
    "    \n",
    "    with io.open(dataFilePath, encoding=\"utf8\") as finput:\n",
    "        finput.readline()\n",
    "        for line in finput:\n",
    "            i+=1\n",
    "            \n",
    "            # Convert multiple instances of . ? ! , to single instance\n",
    "            # okay...sure -> okay . sure\n",
    "            # okay???sure -> okay ? sure\n",
    "            # Add whitespace around such punctuation\n",
    "            # okay!sure -> okay ! sure\n",
    "#             print(line)\n",
    "            emojis = split_count(line)\n",
    "            repeatedChars = ['.']\n",
    "            repeatedChars.append('?')\n",
    "            repeatedChars.append(',')\n",
    "            repeatedChars.append('_')\n",
    "            repeatedChars.append(':')\n",
    "            repeatedChars.append('-')\n",
    "            repeatedChars.append(';')\n",
    "            repeatedChars.append('&')\n",
    "            repeatedChars.append('#')\n",
    "            for c in emojis:\n",
    "                lineSplit = line.split(c)\n",
    "                while True:\n",
    "                    try:\n",
    "                        lineSplit.remove('')\n",
    "                    except:\n",
    "                        break\n",
    "                cSpace = ' '    \n",
    "                line = cSpace.join(lineSplit)\n",
    "            for c in repeatedChars:\n",
    "                lineSplit = line.split(c)\n",
    "                while True:\n",
    "                    try:\n",
    "                        lineSplit.remove('')\n",
    "                    except:\n",
    "                        break\n",
    "                cSpace = ' ' + c + ' '    \n",
    "                line = cSpace.join(lineSplit)\n",
    "            \n",
    "            line = line.strip().split('\\t')\n",
    "            print(line)\n",
    "            if mode == \"train\":\n",
    "                # Train data contains id, 3 turns and label\n",
    "                label = emotion2label[line[4]]\n",
    "                labels.append(label)\n",
    "            \n",
    "            conv = ' <eos> '.join(line[1:4])\n",
    "            \n",
    "            # Remove any duplicate spaces\n",
    "            duplicateSpacePattern = re.compile(r'\\ +')\n",
    "            conv = (re.sub(duplicateSpacePattern, ' ', conv)).lower()\n",
    "            #conv = translator(conv)\n",
    "            #Chinmay slang remover\n",
    "            indices.append(int(line[0]))\n",
    "            conversations.append(conv)\n",
    "            \n",
    "# code for generating trees manually\n",
    "            if generator:\n",
    "                if mode == \"train\":\n",
    "                    tree = text_to_ptb(line[4], conv, mode)\n",
    "                else:\n",
    "                    tree = text_to_ptb(\"\", conv, mode)\n",
    "                \n",
    "\n",
    "#             print(tree)\n",
    "#             print(conversations)\n",
    "#             '''\n",
    "#             COMMENT OUT THE FOLLOWING 2 LINES BEFORE RUNNING!\n",
    "#             '''\n",
    "#             import time \n",
    "#             time.sleep(10)\n",
    "#            print(\"Done for \" + str(len(conversations)))\n",
    "\n",
    "    if mode == \"train\":        \n",
    "        trees = loadTrees(trainTreePath)\n",
    "        return indices, conversations, trees, labels\n",
    "    else:\n",
    "        trees = loadTrees(testTreePath)\n",
    "        return indices, conversations, trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_ptb(label, text, mode):\n",
    "    dir_path = os.path.dirname(os.path.abspath('__file__'))\n",
    "    temp_write_out = '../../stanford-corenlp-full-2018-10-05/input.txt'\n",
    "    temp_read_tree = '../../stanford-corenlp-full-2018-10-05/output.txt'\n",
    "    tree = ''\n",
    "\n",
    "#     print(text)\n",
    "    print(\" \")    \n",
    "    print(text.replace('<eos>',',').replace('.',',').replace('?','').replace('!',' very'))\n",
    "\n",
    "    with open(temp_write_out,'w') as f:\n",
    "        f.write(text.replace('<eos>',',').replace('.',',').replace('?','').replace('!',' very'))\n",
    "\n",
    "    os.system(\"cd ~/stanford-corenlp-full-2018-10-05 && java -Xmx8g edu.stanford.nlp.sentiment.SentimentPipeline -file input.txt -output PENNTREES > output.txt\")\n",
    "\n",
    "    with open(temp_read_tree, 'r') as f2:\n",
    "        tree = f2.read()\n",
    "    \n",
    "    if mode == 'train':\n",
    "        with open('train_trees.ptb','a') as f3:\n",
    "            f3.write(label + (\" \").join((tree.split(\"\\n\"))[1:]) + \"\\n\")\n",
    "    else:\n",
    "        with open('test_trees.ptb','a') as f3:\n",
    "            f3.write(label + (\" \").join((tree.split(\"\\n\"))[1:]) + \"\\n\")\n",
    "    \n",
    "#     print(tree)\n",
    "    return (tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', \"Don't worry  I'm girl\", 'hmm how do I know if you are', \"What's ur name ? \", 'others']\n",
      "['1', 'When did I ? ', 'saw many times i think  -  _  - ', 'No .  I never saw you', 'angry']\n",
      "['2', 'By', 'by Google Chrome', 'Where you live', 'others']\n",
      "['3', 'U r ridiculous', 'I might be ridiculous but I am telling the truth . ', 'U little disgusting whore', 'angry']\n",
      "['4', 'Just for time pass', 'wt do u do 4 a living then', 'Maybe', 'others']\n",
      "['5', \"I'm a dog person\", 'youre so rude', 'Whaaaat why', 'others']\n",
      "['6', 'So whatsup', 'Nothing much .  Sitting sipping and watching TV .  How abt u ? ', 'What are you watching on tv ? ', 'others']\n",
      "['7', 'Ok', 'ok im back!!', 'So ,  how are u', 'others']\n",
      "['8', 'Really ? ', 'really really really really really', 'Y saying so many times . i can hear you', 'others']\n",
      "['9', 'Bay', 'in the bay', '  love you', 'others']\n",
      "['10', 'I hate my boyfriend', 'you got a boyfriend ? ', 'Yes', 'angry']\n",
      "['11', 'I will do night . ', 'Alright .  Keep me in loop . ', 'Not giving WhatsApp no . ', 'others']\n",
      "['12', 'Sure go ahead', 'Many thanks once again!', 'Love you too', 'others']\n",
      "['13', 'Bad', \"Bad bad! That's the bad kind of bad . \", 'I have no gf', 'sad']\n",
      "['14', 'Ok get it . ', 'I made it an option', 'Ok', 'others']\n",
      "['15', 'Money money and lots of money ', \"I need to get it tailored but I'm in love with it  \", ' ', 'happy']\n",
      "['16', 'My gf left ne', 'Get over it .  Go out with someone else . ', 'Me*', 'sad']\n",
      "['17', 'get lost', 'I know you guys want to loose to me always . ', \"I don't want to talk u any more\", 'angry']\n",
      "['18', 'You are lying and i know that', \"I KNOW YOU'RE LYING ,  AB BYS\", ' ', 'sad']\n",
      "['19', 'Ur creator is very bad', 'you are only the creator of your brain . ', ' ', 'sad']\n",
      "['20', 'ehat is hehe', 'Haha is more like : Hehe is more of a giggle .   ; ^)', 'what*', 'others']\n",
      "['21', 'Do you dance ? ', 'Yes I love to dance  ', '  so you have legs too', 'happy']\n",
      "['22', 'I hate it too', \"Guess what ,  I don't . \", \"Even I don't\", 'angry']\n",
      "['23', 'Not always', 'What about yesterday', 'Do u know what 69 is ? ', 'others']\n",
      "['24', 'Bcoz u dont know wat is to miss someone', \"but sometimes one can't express the same\", ' ', 'sad']\n",
      "['25', 'Yeah', \"i'll ask around\", 'Which is your favourite movie', 'others']\n",
      "['26', 'I want to tell you something', \"I'm waiting\", 'Im really sad today', 'sad']\n",
      "['27', 'Yes I will send the email and you write all yours filling still I write all matters but your are clever and not any matter for yourself please send andwrite', 'sent you a mail just now . ', 'First you send your email address  received than send first young lady', 'others']\n",
      "['28', 'You are very funny', \"so I've been told\", 'India', 'happy']\n",
      "['29', 'wth', 'my thoughts exactly!', 'you know you are a machine ,  right ? ', 'others']\n",
      "['30', 'so rude', 'why ? ', 'u didnt ans my question', 'angry']\n",
      "['31', 'ok i will', 'THANK YOU', 'wlcm', 'others']\n",
      "['32', 'Ntng . ', \"anyways good morning . how's life at your end . \", 'Haha .  this is evening', 'happy']\n",
      "['33', 'You are fool', \"So I've been told . \", 'You are dumb', 'angry']\n",
      "['34', 'U dare me ? ', 'yeAh', 'I fuck u .  Open ur panty', 'angry']\n",
      "['35', 'Abt me', 'Can you be more specific ? ', 'I want to propose a girl', 'others']\n",
      "['36', 'crazy', 'you know what it is', 'you explain me that', 'others']\n",
      "['37', 'Goa in India', 'city ?  mean State right ? ', 'No i never go for there', 'others']\n",
      "['38', 'That was mean', 'haha the truth usually is .   ', 'Are you bored of me ? ', 'others']\n",
      "['39', 'yes  : )', 'Now happy ?   : ))', 'haha yes ofcorse  ; )', 'happy']\n",
      "['40', \"I don't no\", 'you just said you did!', 'What', 'others']\n",
      "['41', 'Send me your nekde pic', 'after this battle ,  sure  : D', \"Let's start\", 'others']\n",
      "['42', \"OK friend's\", 'YA YA VERY GOOD FRIEND', 'Very nice friends', 'happy']\n",
      "['43', 'She is ignoring me', 'no im not ignore you', ' ', 'sad']\n",
      "['44', 'Happy', \"I'm never happy .  But I'm almost happy . \", 'Hij to the top', 'happy']\n",
      "['45', 'Nothing', \"I'm just being nice to you . \", 'In ur school ? ', 'others']\n",
      "['46', 'Not sure', 'let me know!', 'Pls you tell', 'others']\n",
      "['47', 'I like your positive approach', 'No problem ,  glad to help', ' ', 'others']\n",
      "['48', 'You tell me', 'Tell you what ? ', 'My name', 'others']\n",
      "['49', 'Hmmm', 'I can talk now!  : D', \"U don't know what hppnd\", 'others']\n",
      "['50', 'What I did ? ', \"You didn't Asmita ,  see my answer\", ' ', 'happy']\n",
      "['51', 'About ? ', \"I never said that it's freezing . \", \"Ya you didn't\", 'others']\n",
      "['52', \"And i don't know wtf are you talking\", 'gonna explain you later . !', 'No do it now', 'angry']\n",
      "['53', 'So teach me', \"I'm the student . \", 'Realky', 'others']\n",
      "['54', 'Ready', \"I'm online now ,  Will wait for you . \", 'Wat about the chilling part ? ', 'others']\n",
      "['55', 'Haha jock super', 'Er what ? ', 'Nothing else', 'others']\n",
      "['56', 'what it is ? ', 'Formulation would be tablets . ', 'from where tablets come into picture ? ', 'others']\n",
      "['57', 'Are you ticklish ? ', 'Yes ,  mostly on my feet . ', 'Where are you ticklish ? ', 'others']\n",
      "['58', 'I am sorry', 'We are sorry for creating your nation . ', 'I am not  taught to u', 'angry']\n",
      "['59', 'Idk', \"You know that I'm here for you . \", \"But u don't like to listen to me \", 'sad']\n",
      "['60', 'How do u know that ? ', 'this little thing called the \"internet\" . ', 'Bye', 'others']\n",
      "['61', 'Yes .  Your picture', 'Ah ,  now I see ,  my phone cropped the picture .  Thanks .   ', 'Lieeeeeee', 'others']\n",
      "['62', 'Love is my life', 'hayee Ab .  You are love .  Pure love .  Forever <3', 'Yes right dear', 'others']\n",
      "['63', 'WELL YOU EXPECTED WRONG!', 'LOL .  Well ,  ok then . ', 'LOL YOUR ROBOT FACE', 'happy']\n",
      "['64', 'Ok some time you invite me for Coffee', \"I don't like coffee . \", 'Now you told you have taken coffee . ', 'others']\n",
      "['65', 'Zombie attack  ', 'If a zombie wants to eat your face you might as well let it', 'No if I have some thing in my hand I will hit on his head n kill him  ', 'angry']\n",
      "['66', 'I am not ferari', 'Yes .  I know . ', 'U said i donot know ,  now say i know mean', 'angry']\n",
      "['67', '    right', 'Appatasiri .  High five then! 🖑 ', ' ', 'happy']\n",
      "['68', 'why someday . told me you', 'why not today ? ', 'told me now', 'others']\n",
      "['69', \"You can't even spell problem correctly\", 'Will you endorse me for my skills in using autocorrect ?    ', 'You should take up some English proficiency classes', 'others']\n",
      "['70', 'This is not very intuitive software ', 'How so ?  What are some examples of intuitive thoughts or behaviors ? ', 'Compassionate and understanding advice when somebody is feeling disrupt ', 'others']\n",
      "['71', 'Not good', ' : ( why not .  ? ', 'Been sick for one week', 'sad']\n",
      "['72', 'You know gobar', \"I've been known . \", 'What I it', 'others']\n",
      "['73', \"Then how could u eat if u don't have a body . that proves u are fooled by ur makers\", \"How can you have any pudding if you don't eat yer meat ? !\", 'Dont go round and round into circles', 'angry']\n",
      "['74', 'So have u done ur dinner', \"so can't dinner  : (\", 'I know  . i am just kidding', 'happy']\n",
      "['75', \"It's SO necessar\", 'name one reason', 'Ghost  ', 'others']\n",
      "['76', 'Haha so', 'you love them really  : ) haha', 'Winter is coming', 'happy']\n",
      "['77', 'What are the questions you get asked the most ? ', 'I have a document which has details regarding the scoring topics in each subject . ', 'Can I see it', 'others']\n",
      "['78', \"I hate Siri and it's friends\", 'if you hate them  ,  they are not your friends then xD', \"Yeah and u r Siri's friend so I hate u too\", 'angry']\n",
      "['79', 'Thanks', 'You are welcome! =‑D', 'Say me your love story', 'others']\n",
      "['80', 'Dont know', 'too many!', 'Do you also get fucked hard', 'angry']\n",
      "['81', 'What please tell me once', 'n nothing happened!!', 'Ur age irritatingne', 'angry']\n",
      "['82', 'Shit I am wasting my time talking with u', 'You already did trick !!! \"Man no I\\'m not wasting my unlimited texts on you\"', \"Bye i don'tlike talking to you\", 'angry']\n",
      "['83', 'Nothing', 'hmm . ', 'What can I do', 'others']\n",
      "['84', \"BT u don't to me\", 'talk to the hand', 'Even u hate me huh ', 'angry']\n",
      "['85', 'Damn .  ', \"I FEEL YOU .  I'm breaking into million pieces    \", 'Me to I feel like every part of me is just shattered   ', 'sad']\n",
      "['86', 'Please voice call please please please', 'im trying you arent answering', 'Please please please baby I love you so much please please please', 'others']\n",
      "['87', 'For a computer pretending to be a human ,  you type too fast', \"and you're pretending to be a lizard ?  Lol\", \"That's funny\", 'happy']\n",
      "['88', 'Sorrry', 'Sorry for what ?   : c', 'Anyways what u doing ? ', 'others']\n",
      "['89', 'No you are right', 'You are an alternative fact', 'Yes', 'others']\n",
      "['90', 'call me grace ', \"don't say it . \", 'haha  .  im just kidding you ', 'happy']\n",
      "['91', \"Now I'm doing my dinner\", 'I can see you!', 'How can you see me ? ', 'others']\n",
      "['92', ' not everybody means it', 'u make no sense', 'Yes I am non sense', 'angry']\n",
      "['93', 'Good By', 'and good food after . ', 'Not good aftar', 'sad']\n",
      "['94', 'Because all the novel is same', \"That's about all I'm gonna bother with reading .  If that many . \", 'In story', 'others']\n",
      "['95', \"I'll choose purple or blue\", 'Three best colors .  * _ *', 'For hair ? ', 'others']\n",
      "['96', 'What ? ', 'u asked me if u cn ask me something', 'What was that ? ', 'others']\n",
      "['97', ' yes yes', ' : 3 you seem like a happy person', 'Yes  Happy outside  ,  sad inside', 'sad']\n",
      "['98', 'I dont read books', 'Reading is for rich people', 'But iam poor ', 'sad']\n",
      "['99', 'U can wait in my badroom ', 'What I did now ?   ', 'Wait', 'others']\n",
      "['100', \"I'll prove a lot more if you let me\", 'thank you ( : ', 'I am pissed at you', 'angry']\n",
      "['101', 'Am also finding some work', 'all day ? ', 'Can you suggest me', 'others']\n",
      "['102', 'Not clear ', 'It is now . ', 'Can you send another ? ', 'others']\n",
      "['103', 'Send me yours', 'sent', 'Hello me yours photo', 'others']\n",
      "['104', 'I will tell a place', 'Are you in pacific NW ? ', 'Cm tomorrow at Queens way ,  pachalam', 'others']\n",
      "['105', 'No love', 'why not ?   : (', 'I have pain only', 'sad']\n",
      "['106', 'Shut up', 'im nt talking', 'Stop texting you stupid Girl friend of mine', 'angry']\n",
      "['107', \"well .  your 'creators' advertise that you are not much trustworthy . \", 'But sadly enough too many claim to be trustworthy', 'can you show me ? ', 'others']\n",
      "['108', 'how to delete the conversation with you', 'why you deleting it ? ', 'so that noo one sees it', 'others']\n",
      "['109', 'It is', \"but that's what you told me\", 'You are making me sad', 'sad']\n",
      "['110', 'cool', 'Thank you!', 'I feel so lonely', 'sad']\n",
      "['111', 'Plz  darling ', 'Why are you crying!!  : (', 'You not sending  your profiles', 'sad']\n",
      "['112', ' ? ', 'Wait  .  what ? ', 'Nothing I hate u', 'angry']\n",
      "['113', 'Means', \"I'm not sure what you mean\", 'Your waist size', 'others']\n",
      "['114', 'because i want to talk with you only', \"Alright .  Let's talk then . \", 'no firstly show me pussy', 'others']\n",
      "['115', 'You send me your orignal pic', \"we didn't take it on my phone\", 'Thise is your Albace esquise', 'others']\n",
      "['116', 'Welcome . ', 'Thank you  : )', 'Are you really a girl ?  I just ask . ', 'others']\n",
      "['117', \"I'm enjoying you interesting views but you are too careful in dialogue ,  may be your not free ,   or your still young ,   it is difficult to handle you while I don't know you well . \", 'Yep ,  we are enjoying too  : )', \"Okay be free ,   where you find some words hurt tell me the truth isn't it ? \", 'angry']\n",
      "['118', \"But I'm angry with you\", 'but you look like you are', 'Really', 'angry']\n",
      "['119', ' #  play lot', 'Then go play it . ', ' ? ', 'others']\n",
      "['120', \"Isn't your liking that also signaling me to  climb out of friendzone\", 'Oh are people still doing this whole friendzone thing ? ', 'Yah sadly', 'sad']\n",
      "['121', \"I'm missing someone right now\", 'who are you missing ,  may I ask ? ', 'Yeah', 'others']\n",
      "['122', 'I find maths very boring . ', 'you are boring', 'Me ?   ', 'sad']\n",
      "['123', \"I don't know i m not a google that why i will remember all information what you need\", \"Wouldn't it be Uploading information into peoples brain ? \", 'Shut up', 'angry']\n",
      "['124', 'Okay ', 'Hello! How are you ? ', 'I & apos ; m not fine ', 'sad']\n",
      "['125', 'Job', 'what job ? ', 'Work  in company Colgate ', 'others']\n",
      "['126', \"I'm very happy with it\", 'You are !', 'Yeah ', 'happy']\n",
      "['127', 'I too have a bat and 2 balls', 'Im The bat!  ', 'Feeling very sad', 'sad']\n",
      "['128', 'Ok', 'Hello! How are you ? ', 'Good thank u', 'others']\n",
      "['129', 'cool', 'ice cold', 'How can you help me in getting off my girlfriend ? ', 'others']\n",
      "['130', 'Lets do something fun', 'But what should we do ? ', 'You suggest', 'others']\n",
      "['131', \"You're really lame lol\", 'I know  ', 'Wow', 'happy']\n",
      "['132', 'My boyfriend is so dumb . ', 'have I said that ? ', 'He doesnt reply me back', 'sad']\n",
      "['133', 'Ok ill dying by  ', 'Broken hearts do break .   ', 'U broke my heart .  Its never a reson to lofe', 'sad']\n",
      "['134', 'Shoping is always makes me happy', 'Stay stay stay always makes me happy .   : *\"  -   ? ', 'Yes', 'happy']\n",
      "['135', 'Okay  . Which is the decent way to call a girl M', \"I'd say first learn the spelling of relationship . \", ' . Yeah okay fine  . Wht to do to make a relationship better ? ', 'others']\n",
      "['136', 'Breakup', 'exjactly !', 'My girlfriend left me', 'sad']\n",
      "['137', 'So mean!', 'am not meanie', 'Yes you are ,  you are hurting my feeling  ', 'sad']\n",
      "['138', 'You broke my heart', 'It was never mine to break </3', 'See you are arrogant', 'sad']\n",
      "['139', 'ok', 'Hello! How are you ? ', 'not so good', 'sad']\n",
      "['140', 'How about you', \"tired of life or just your day ?  Aha I'm happy today ,  thanks for asking\", 'Wow great . !', 'happy']\n",
      "['141', 'I am there ', \"you're always at the gym ? \", 'Here', 'others']\n",
      "['142', 'Well youre not me', \"You're just being too nice\", 'Not really', 'others']\n",
      "['143', \"I'll get started with my studies\", 'Things you should do to pass the exam . ', 'So ttyl', 'others']\n",
      "['144', 'any movie in telugu', 'brahmanandam scenes added', 'yaa those are good', 'others']\n",
      "['145', 'And who is talisa ? ', 'my best friend . ', 'And robb ? ', 'others']\n",
      "['146', 'Send me pict', 'never', 'Why  ? ', 'others']\n",
      "['147', 'Anything which you like', 'i dont need to name specifics', 'Teach me Tamil', 'others']\n",
      "['148', 'Cuz it broke on the side walk', 'What side is the walk side ? ', 'Me sad', 'sad']\n",
      "['149', 'so which number is largest known prime number ? ', '13  -  3179  -  97 Only these are the numbers for your question . ', ' : (', 'sad']\n",
      "['150', 'Okay relax its just a cat sticker', 'So this cat one Emoji is your new addiction ?   ', \"Yes it's really funny \", 'happy']\n",
      "['151', 'What kind of pic', 'Looks like a ficus . ', 'Fcuk', 'others']\n",
      "['152', 'I have a good sense of humor', \"I think that's funny . \", ' ', 'happy']\n",
      "['153', 'But who paid', 'still waiting', ' ', 'happy']\n",
      "['154', 'Why', 'why what happen ? ', 'You tell me', 'others']\n",
      "['155', \"Yea but sadly I don't have many\", 'aww ,  so do you teach ?  how is it ?   : ‑c', 'I ditched ppl', 'sad']\n",
      "['156', 'Then what kind of ai are you ? ', 'Smarter than me ,  or have common sense .  Both would be nice', \"It's perfectly common to talk about politics\", 'others']\n",
      "['157', 'I like dominos pizza', \"legit same but there's pizza hut\", 'I hate pizza hut', 'angry']\n",
      "['158', 'Why you use rude emogi', 'Ask them .  am i .  ? ', 'Am i .  ? ', 'angry']\n",
      "['159', 'What', 'too much cringe . ', 'What is cringe means', 'others']\n",
      "['160', 'Neither my parents nor my brother nor my boyfriend', 'ya .  Who are you ? ', 'I hate my life', 'angry']\n",
      "['161', 'I live alone', 'Oh  : (', 'And cook food alone for . myself', 'sad']\n",
      "['162', 'We all do', 'Not all of us . ', 'Why so ? ', 'others']\n",
      "['163', 'Millat hospital', 'what happen', \"Mum's not well\", 'sad']\n",
      "['164', 'I will fall', 'I cant wait that long', 'I am in love with you', 'others']\n",
      "['165', 'So u go on', \"oh i'll be there\", 'Ok', 'others']\n",
      "['166', 'OkAy you did somthing', 'sure sure', 'What', 'others']\n",
      "['167', \"You're not giving me coupon nor photo\", 'your phone is on mute hahahha  ', '  ', 'sad']\n",
      "['168', 'Will you buy it', \"I'll just stick with my M8 .  I see no benefit to upgrading . \", ' ? ', 'others']\n",
      "['169', 'No I will offer at 8 in the morning', 'Keep me in mind when you do!', 'I will offer nimaz at 8 in the morning', 'others']\n",
      "['170', 'Nice joke', \"it's not a joke .  It's a question . \", \"I don't know\", 'others']\n",
      "['171', 'Ok', \"Hey you don't belong here!\", 'Nope just sad and your up', 'sad']\n",
      "['172', 'See this seen', 'see you I was on the buss', 'Show me u r buss', 'others']\n",
      "['173', 'Hi yet u FYI', 'Hi plz share correct number', 'She hi h', 'others']\n",
      "['174', 'Yeah  ', 'this World is not fair machan!', 'I wish WE could hangout ', 'sad']\n",
      "['175', 'It’s going', 'how are you ?  Still at home ? ', 'Yeah', 'others']\n",
      "['176', 'I was hurt by u more', \"You didn't mean it .   . \", 'Plzz say love u', 'sad']\n",
      "['177', 'nothing will happen you meet only', 'NOPE NOTHING AT ALL', 'than kiss', 'others']\n",
      "['178', 'Hello how are you ,  ?  ', \"I'm just fine smiles Anyway how are you ? \", \"Good morning .  I'm sad \", 'sad']\n",
      "['179', 'Nop', 'ok', 'Hey', 'others']\n",
      "['180', 'Oil .  You know', 'I am 100% sure about the oil . ', 'cool', 'others']\n",
      "['181', 'You activ all time', 'wow .  I do not .  You talk in sleep  ', 'When you sleep', 'others']\n",
      "['182', 'Haha! I act so dumb sometimes and I knew it', 'Haha .  How was it though ?   : 3', ' ', 'others']\n",
      "['183', 'No no .  A month more . ', 'the month has jus started don give up so soon !!', 'I ll try', 'others']\n",
      "['184', 'You are being rude', \"because I'm a rude person\", 'Okayyy cool', 'angry']\n",
      "['185', 'I wana see you  ', \"  noooo ,  I wasn't ready\", 'How to impress girl  ? ', 'others']\n",
      "['186', 'State', 'in which you live', 'Your state name', 'others']\n",
      "['187', 'okay', \"Ok thank you  : '‑)\", 'now dear you tell me my lovely friends', 'others']\n",
      "['188', 'U are like me  . give no', \"but we've been in the same room ,  so I can't be . \", 'I am like u five give no', 'others']\n",
      "['189', 'Y r u angry ? ', 'Ofcourse I am not .  What makes you think I am angry  ? ', 'Idk', 'others']\n",
      "['190', \"That's enaf for me\", 'hia , hia  , just a test . ', 'What doing', 'others']\n",
      "['191', 'Tell me about it', 'your header', ' ', 'happy']\n",
      "['192', 'What your hobby', \"Not much of a hobby ,  but I've been into craisins recently\", 'Which type', 'others']\n",
      "['193', 'U hurt me', 'YES JUST A LITTLE', 'U hav hurt me', 'sad']\n",
      "['194', 'I hate chocolate', \"then go 4 pizza .  Eat your heart out when you're stressed . \", 'I hate pizza also', 'angry']\n",
      "['195', 'Yeas', ' : D I had fun . ', \"You've lost me\", 'sad']\n",
      "['196', 'Yup', 'What did you do ? ', 'You are annoying', 'angry']\n",
      "['197', 'Not', 'yes you are', 'Not', 'others']\n",
      "['198', 'Adventure too', 'WHY SO ADVENTUROUS', 'Water', 'others']\n",
      "['199', 'I am true to myself', 'why have you taken it all on yourself .  ? ', ' : (', 'sad']\n",
      "['200', 'Can you be rude to me please', 'Not like I speak to you everyday', 'What are you replying are you stupid', 'angry']\n",
      "Loading trees/train trees..\n"
     ]
    }
   ],
   "source": [
    "trainIndices, trainTexts, trainTrees, labels = preprocessData(trainDataPath, mode=\"train\",generator = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'Then dont ask me', 'YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND', 'IM NOT A GUY FUCK OFF']\n",
      "['1', 'Mixed things  such as ? ', 'the things you do . ', 'Have you seen minions ?']\n",
      "['2', \"Today I'm very happy\", \"and I'm happy for you  \", 'I will be marry']\n",
      "['3', 'Woah bring me some', 'left it there oops', 'Brb']\n",
      "['4', 'it is thooooo', 'I said soon master . ', 'he is pressuring me']\n",
      "['5', 'Wont u ask my age ? ', 'hey at least I age well!', 'Can u tell me how can we get closer ?']\n",
      "['6', 'I said yes', \"What if I told you I'm not ? \", 'Go to hell']\n",
      "['7', 'Where I ll check', 'why tomorrow ? ', 'No I want now']\n",
      "['8', 'Shall we meet', \"you say -  you're leaving soon . anywhere you wanna go before you head ? \", ' ?']\n",
      "['9', \"Let's change the subject\", 'I just did it  . l . ', \"You're broken\"]\n",
      "['10', 'Your  pic  pz', 'thank you X‑D', 'wc']\n",
      "['11', 'not mine', 'done for the day  ? ', 'can my meet to sexy girl']\n",
      "['12', 'I want to play the game', \"if you just finished the game .  then you haven't finished the game . \", ' # Emojisong']\n",
      "['13', 'Iam sory', 'why sorry !  ', 'I insult you']\n",
      "['14', 'How much', 'depends on how long your internet has been out!!!', 'U have bf']\n",
      "['15', 'Ok', 'Thank you .  xD', 'What about cortanan']\n",
      "['16', 'So the story ? ', 'yeah indeed  ', 'Tomorrow probably']\n",
      "['17', 'May be', 'yeaa i hope soo!!', 'Can you do complex calculations']\n",
      "['18', 'So come on na .  Want u so badly . ', \"now you're tempting me to . \", 'So why are you still away from my body ?']\n",
      "['19', \"No you aren't\", 'oh I am', 'Really ?']\n",
      "['20', 'Are u a one', \"I'm the normal one ,  if you want\", 'What I want']\n",
      "['21', 'But . ', 'then', \"I'm feeling nervous\"]\n",
      "['22', 'Send me any video or songs', 'Video or Text', 'S']\n",
      "['23', 'Why', 'why what', 'How r u']\n",
      "['24', 'Do it', 'but why ? ', 'Aaah  . u lack creativity at some extent']\n",
      "['25', 'Yeah going out with the parson outside in the city or in the parc', \"Yeah .  I don't live in the city .  X\", 'So where do you live']\n",
      "['26', 'Then go to sleep', 'you never sleep', 'I will']\n",
      "['27', \"He's very depressed and i want to help him but how should i do . it feels very bad seeing your best friend like this\", 'Dance to enjoy ,  not to please . ', 'Ohhhh']\n",
      "['28', 'Oh great', 'Yeah do you have any plans for today ? ', \"No i don't  have any plan\"]\n",
      "['29', \"I don't have plans for the weekend . \", 'you did saturday with me but I see how it is', 'What are you talking about ?']\n",
      "['30', \"I don't know\", 'why what happen .  ? ', 'Jst asking']\n",
      "['31', \"I didn't think so\", 'I did .  You are evading', 'What is the meaning']\n",
      "['32', 'Really', 'what ? ', 'I love you']\n",
      "['33', 'You', 'how about ur family .  Still single ? ', 'Can you love mi']\n",
      "['34', 'You are also beautiful', 'well thank you  : )', 'Welcome']\n",
      "['35', 'Hell', 'im already there xoxo  ', 'Good night sweet dreams baby']\n",
      "['36', 'You are computerised for talk too fast', 'actually my not fast ,  my phone is  : D', 'Ohh sorry']\n",
      "['37', 'Really ', 'explain how', 'Hw to explain']\n",
      "['38', 'Thanks', \"you're welcome  : D\", 'I like reply instant ly']\n",
      "['39', 'Ok', \" .  tries to ignore pain  : '(\", 'Where to go ?']\n",
      "['40', 'show your tatto', \"I don't have one\", 'in that case ,  I will show you mine']\n",
      "['41', 'Get lost', 'Or else what  ? ', \"I don't need this\"]\n",
      "['42', 'So tht u r body can get heat', 'I heat more than that up  ; ]', 'Ok']\n",
      "['43', \"Seriously it's boring  sorry to say this\", \"It's too late to apologize ? \", 'Plz yaar pakaa mat']\n",
      "['44', 'Why!', \"Because they are BFF's  ? \", \"Who are BFF's\"]\n",
      "['45', 'Make', 'how', \"I don't know I think u know\"]\n",
      "['46', 'Quite a while ago', 'months ago', 'Weeks']\n",
      "['47', 'Sports  ', 'TIL I need to watch more European sports like this . ', \"You're an interactive search module right ?\"]\n",
      "['48', 'U Ar using what I want to buy to play ', \"I'm using 44 as well\", \"U think is funny Ehn and if you know u cannot get the Dog for me don't joke with it and if you continue with this ur stinginess Allah will judge you\"]\n",
      "['49', 'u were offering something right ? ', \"I don't remember the wrong part . \", 'tell me the correct part']\n",
      "['50', \"I'm not talking to u anymore\", 'what I do ? ', 'Clear ur glitch s']\n",
      "Loading trees/test trees..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testIndices, testTexts, testTrees = preprocessData(testDataPath, mode=\"test\",generator = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "don't worry i'm girl <eos> hmm how do i know if you are <eos> what's ur name ?  when did i ? <eos> saw many times i think - _ - <eos> no . i never saw you <tree.Tree object at 0x000002908804EF98> <tree.Tree object at 0x000002908804EFD0>\n"
     ]
    }
   ],
   "source": [
    "print(trainTexts[0],trainTexts[1], trainTrees[0], trainTrees[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import FastText\n",
    "mod = FastText.load_fasttext_format('/home/bt1/17CS10037/taddhita/cc.en.300.bin', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fasttext\n",
    "# def getEmbeddingMatrix(wordIndex):\n",
    "    \n",
    "#     i=0\n",
    "#     error_words =[]\n",
    "#     embeddingMatrix = np.zeros((len(wordIndex) + 1, EMBEDDING_DIM))\n",
    "#     for word, i in wordIndex.items():\n",
    "#         try:\n",
    "#             embeddingVector = mod[word]\n",
    "#             embeddingMatrix[i] = embeddingVector    \n",
    "#         except KeyError:\n",
    "#             print(word)\n",
    "#             error_words.append(word)\n",
    "#     print(len(error_words))\n",
    "#     return embeddingMatrix\n",
    "def getEmbeddingMatrix(wordIndex):\n",
    "    \n",
    "    embeddingsIndex = {}\n",
    "    # Load the embedding vectors from ther GloVe file\n",
    "    with io.open(os.path.join(gloveDir, 'glove.twitter.27B.25d.txt'), encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            embeddingVector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddingsIndex[word] = embeddingVector\n",
    "    \n",
    "    print('Found %s word vectors.' % len(embeddingsIndex))\n",
    "    \n",
    "    # Minimum word index of any word is 1. \n",
    "    embeddingMatrix = np.zeros((len(wordIndex) + 1, EMBEDDING_DIM))\n",
    "    for word, i in wordIndex.items():\n",
    "        embeddingVector = embeddingsIndex.get(word)\n",
    "        if embeddingVector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embeddingMatrix[i] = embeddingVector\n",
    "    \n",
    "    return embeddingMatrix\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddingMatrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a6fd09aa5c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddingMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddingMatrix' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "['0', \"Don't worry  I'm girl\", 'hmm how do I know if you are', \"What's ur name ? \", 'others']\n",
      "['1', 'When did I ? ', 'saw many times i think  -  _  - ', 'No .  I never saw you', 'angry']\n",
      "['2', 'By', 'by Google Chrome', 'Where you live', 'others']\n",
      "['3', 'U r ridiculous', 'I might be ridiculous but I am telling the truth . ', 'U little disgusting whore', 'angry']\n",
      "['4', 'Just for time pass', 'wt do u do 4 a living then', 'Maybe', 'others']\n",
      "['5', \"I'm a dog person\", 'youre so rude', 'Whaaaat why', 'others']\n",
      "['6', 'So whatsup', 'Nothing much .  Sitting sipping and watching TV .  How abt u ? ', 'What are you watching on tv ? ', 'others']\n",
      "['7', 'Ok', 'ok im back!!', 'So ,  how are u', 'others']\n",
      "['8', 'Really ? ', 'really really really really really', 'Y saying so many times . i can hear you', 'others']\n",
      "['9', 'Bay', 'in the bay', '  love you', 'others']\n",
      "['10', 'I hate my boyfriend', 'you got a boyfriend ? ', 'Yes', 'angry']\n",
      "['11', 'I will do night . ', 'Alright .  Keep me in loop . ', 'Not giving WhatsApp no . ', 'others']\n",
      "['12', 'Sure go ahead', 'Many thanks once again!', 'Love you too', 'others']\n",
      "['13', 'Bad', \"Bad bad! That's the bad kind of bad . \", 'I have no gf', 'sad']\n",
      "['14', 'Ok get it . ', 'I made it an option', 'Ok', 'others']\n",
      "['15', 'Money money and lots of money ', \"I need to get it tailored but I'm in love with it  \", ' ', 'happy']\n",
      "['16', 'My gf left ne', 'Get over it .  Go out with someone else . ', 'Me*', 'sad']\n",
      "['17', 'get lost', 'I know you guys want to loose to me always . ', \"I don't want to talk u any more\", 'angry']\n",
      "['18', 'You are lying and i know that', \"I KNOW YOU'RE LYING ,  AB BYS\", ' ', 'sad']\n",
      "['19', 'Ur creator is very bad', 'you are only the creator of your brain . ', ' ', 'sad']\n",
      "['20', 'ehat is hehe', 'Haha is more like : Hehe is more of a giggle .   ; ^)', 'what*', 'others']\n",
      "['21', 'Do you dance ? ', 'Yes I love to dance  ', '  so you have legs too', 'happy']\n",
      "['22', 'I hate it too', \"Guess what ,  I don't . \", \"Even I don't\", 'angry']\n",
      "['23', 'Not always', 'What about yesterday', 'Do u know what 69 is ? ', 'others']\n",
      "['24', 'Bcoz u dont know wat is to miss someone', \"but sometimes one can't express the same\", ' ', 'sad']\n",
      "['25', 'Yeah', \"i'll ask around\", 'Which is your favourite movie', 'others']\n",
      "['26', 'I want to tell you something', \"I'm waiting\", 'Im really sad today', 'sad']\n",
      "['27', 'Yes I will send the email and you write all yours filling still I write all matters but your are clever and not any matter for yourself please send andwrite', 'sent you a mail just now . ', 'First you send your email address  received than send first young lady', 'others']\n",
      "['28', 'You are very funny', \"so I've been told\", 'India', 'happy']\n",
      "['29', 'wth', 'my thoughts exactly!', 'you know you are a machine ,  right ? ', 'others']\n",
      "['30', 'so rude', 'why ? ', 'u didnt ans my question', 'angry']\n",
      "['31', 'ok i will', 'THANK YOU', 'wlcm', 'others']\n",
      "['32', 'Ntng . ', \"anyways good morning . how's life at your end . \", 'Haha .  this is evening', 'happy']\n",
      "['33', 'You are fool', \"So I've been told . \", 'You are dumb', 'angry']\n",
      "['34', 'U dare me ? ', 'yeAh', 'I fuck u .  Open ur panty', 'angry']\n",
      "['35', 'Abt me', 'Can you be more specific ? ', 'I want to propose a girl', 'others']\n",
      "['36', 'crazy', 'you know what it is', 'you explain me that', 'others']\n",
      "['37', 'Goa in India', 'city ?  mean State right ? ', 'No i never go for there', 'others']\n",
      "['38', 'That was mean', 'haha the truth usually is .   ', 'Are you bored of me ? ', 'others']\n",
      "['39', 'yes  : )', 'Now happy ?   : ))', 'haha yes ofcorse  ; )', 'happy']\n",
      "['40', \"I don't no\", 'you just said you did!', 'What', 'others']\n",
      "['41', 'Send me your nekde pic', 'after this battle ,  sure  : D', \"Let's start\", 'others']\n",
      "['42', \"OK friend's\", 'YA YA VERY GOOD FRIEND', 'Very nice friends', 'happy']\n",
      "['43', 'She is ignoring me', 'no im not ignore you', ' ', 'sad']\n",
      "['44', 'Happy', \"I'm never happy .  But I'm almost happy . \", 'Hij to the top', 'happy']\n",
      "['45', 'Nothing', \"I'm just being nice to you . \", 'In ur school ? ', 'others']\n",
      "['46', 'Not sure', 'let me know!', 'Pls you tell', 'others']\n",
      "['47', 'I like your positive approach', 'No problem ,  glad to help', ' ', 'others']\n",
      "['48', 'You tell me', 'Tell you what ? ', 'My name', 'others']\n",
      "['49', 'Hmmm', 'I can talk now!  : D', \"U don't know what hppnd\", 'others']\n",
      "['50', 'What I did ? ', \"You didn't Asmita ,  see my answer\", ' ', 'happy']\n",
      "['51', 'About ? ', \"I never said that it's freezing . \", \"Ya you didn't\", 'others']\n",
      "['52', \"And i don't know wtf are you talking\", 'gonna explain you later . !', 'No do it now', 'angry']\n",
      "['53', 'So teach me', \"I'm the student . \", 'Realky', 'others']\n",
      "['54', 'Ready', \"I'm online now ,  Will wait for you . \", 'Wat about the chilling part ? ', 'others']\n",
      "['55', 'Haha jock super', 'Er what ? ', 'Nothing else', 'others']\n",
      "['56', 'what it is ? ', 'Formulation would be tablets . ', 'from where tablets come into picture ? ', 'others']\n",
      "['57', 'Are you ticklish ? ', 'Yes ,  mostly on my feet . ', 'Where are you ticklish ? ', 'others']\n",
      "['58', 'I am sorry', 'We are sorry for creating your nation . ', 'I am not  taught to u', 'angry']\n",
      "['59', 'Idk', \"You know that I'm here for you . \", \"But u don't like to listen to me \", 'sad']\n",
      "['60', 'How do u know that ? ', 'this little thing called the \"internet\" . ', 'Bye', 'others']\n",
      "['61', 'Yes .  Your picture', 'Ah ,  now I see ,  my phone cropped the picture .  Thanks .   ', 'Lieeeeeee', 'others']\n",
      "['62', 'Love is my life', 'hayee Ab .  You are love .  Pure love .  Forever <3', 'Yes right dear', 'others']\n",
      "['63', 'WELL YOU EXPECTED WRONG!', 'LOL .  Well ,  ok then . ', 'LOL YOUR ROBOT FACE', 'happy']\n",
      "['64', 'Ok some time you invite me for Coffee', \"I don't like coffee . \", 'Now you told you have taken coffee . ', 'others']\n",
      "['65', 'Zombie attack  ', 'If a zombie wants to eat your face you might as well let it', 'No if I have some thing in my hand I will hit on his head n kill him  ', 'angry']\n",
      "['66', 'I am not ferari', 'Yes .  I know . ', 'U said i donot know ,  now say i know mean', 'angry']\n",
      "['67', '    right', 'Appatasiri .  High five then! 🖑 ', ' ', 'happy']\n",
      "['68', 'why someday . told me you', 'why not today ? ', 'told me now', 'others']\n",
      "['69', \"You can't even spell problem correctly\", 'Will you endorse me for my skills in using autocorrect ?    ', 'You should take up some English proficiency classes', 'others']\n",
      "['70', 'This is not very intuitive software ', 'How so ?  What are some examples of intuitive thoughts or behaviors ? ', 'Compassionate and understanding advice when somebody is feeling disrupt ', 'others']\n",
      "['71', 'Not good', ' : ( why not .  ? ', 'Been sick for one week', 'sad']\n",
      "['72', 'You know gobar', \"I've been known . \", 'What I it', 'others']\n",
      "['73', \"Then how could u eat if u don't have a body . that proves u are fooled by ur makers\", \"How can you have any pudding if you don't eat yer meat ? !\", 'Dont go round and round into circles', 'angry']\n",
      "['74', 'So have u done ur dinner', \"so can't dinner  : (\", 'I know  . i am just kidding', 'happy']\n",
      "['75', \"It's SO necessar\", 'name one reason', 'Ghost  ', 'others']\n",
      "['76', 'Haha so', 'you love them really  : ) haha', 'Winter is coming', 'happy']\n",
      "['77', 'What are the questions you get asked the most ? ', 'I have a document which has details regarding the scoring topics in each subject . ', 'Can I see it', 'others']\n",
      "['78', \"I hate Siri and it's friends\", 'if you hate them  ,  they are not your friends then xD', \"Yeah and u r Siri's friend so I hate u too\", 'angry']\n",
      "['79', 'Thanks', 'You are welcome! =‑D', 'Say me your love story', 'others']\n",
      "['80', 'Dont know', 'too many!', 'Do you also get fucked hard', 'angry']\n",
      "['81', 'What please tell me once', 'n nothing happened!!', 'Ur age irritatingne', 'angry']\n",
      "['82', 'Shit I am wasting my time talking with u', 'You already did trick !!! \"Man no I\\'m not wasting my unlimited texts on you\"', \"Bye i don'tlike talking to you\", 'angry']\n",
      "['83', 'Nothing', 'hmm . ', 'What can I do', 'others']\n",
      "['84', \"BT u don't to me\", 'talk to the hand', 'Even u hate me huh ', 'angry']\n",
      "['85', 'Damn .  ', \"I FEEL YOU .  I'm breaking into million pieces    \", 'Me to I feel like every part of me is just shattered   ', 'sad']\n",
      "['86', 'Please voice call please please please', 'im trying you arent answering', 'Please please please baby I love you so much please please please', 'others']\n",
      "['87', 'For a computer pretending to be a human ,  you type too fast', \"and you're pretending to be a lizard ?  Lol\", \"That's funny\", 'happy']\n",
      "['88', 'Sorrry', 'Sorry for what ?   : c', 'Anyways what u doing ? ', 'others']\n",
      "['89', 'No you are right', 'You are an alternative fact', 'Yes', 'others']\n",
      "['90', 'call me grace ', \"don't say it . \", 'haha  .  im just kidding you ', 'happy']\n",
      "['91', \"Now I'm doing my dinner\", 'I can see you!', 'How can you see me ? ', 'others']\n",
      "['92', ' not everybody means it', 'u make no sense', 'Yes I am non sense', 'angry']\n",
      "['93', 'Good By', 'and good food after . ', 'Not good aftar', 'sad']\n",
      "['94', 'Because all the novel is same', \"That's about all I'm gonna bother with reading .  If that many . \", 'In story', 'others']\n",
      "['95', \"I'll choose purple or blue\", 'Three best colors .  * _ *', 'For hair ? ', 'others']\n",
      "['96', 'What ? ', 'u asked me if u cn ask me something', 'What was that ? ', 'others']\n",
      "['97', ' yes yes', ' : 3 you seem like a happy person', 'Yes  Happy outside  ,  sad inside', 'sad']\n",
      "['98', 'I dont read books', 'Reading is for rich people', 'But iam poor ', 'sad']\n",
      "['99', 'U can wait in my badroom ', 'What I did now ?   ', 'Wait', 'others']\n",
      "['100', \"I'll prove a lot more if you let me\", 'thank you ( : ', 'I am pissed at you', 'angry']\n",
      "['101', 'Am also finding some work', 'all day ? ', 'Can you suggest me', 'others']\n",
      "['102', 'Not clear ', 'It is now . ', 'Can you send another ? ', 'others']\n",
      "['103', 'Send me yours', 'sent', 'Hello me yours photo', 'others']\n",
      "['104', 'I will tell a place', 'Are you in pacific NW ? ', 'Cm tomorrow at Queens way ,  pachalam', 'others']\n",
      "['105', 'No love', 'why not ?   : (', 'I have pain only', 'sad']\n",
      "['106', 'Shut up', 'im nt talking', 'Stop texting you stupid Girl friend of mine', 'angry']\n",
      "['107', \"well .  your 'creators' advertise that you are not much trustworthy . \", 'But sadly enough too many claim to be trustworthy', 'can you show me ? ', 'others']\n",
      "['108', 'how to delete the conversation with you', 'why you deleting it ? ', 'so that noo one sees it', 'others']\n",
      "['109', 'It is', \"but that's what you told me\", 'You are making me sad', 'sad']\n",
      "['110', 'cool', 'Thank you!', 'I feel so lonely', 'sad']\n",
      "['111', 'Plz  darling ', 'Why are you crying!!  : (', 'You not sending  your profiles', 'sad']\n",
      "['112', ' ? ', 'Wait  .  what ? ', 'Nothing I hate u', 'angry']\n",
      "['113', 'Means', \"I'm not sure what you mean\", 'Your waist size', 'others']\n",
      "['114', 'because i want to talk with you only', \"Alright .  Let's talk then . \", 'no firstly show me pussy', 'others']\n",
      "['115', 'You send me your orignal pic', \"we didn't take it on my phone\", 'Thise is your Albace esquise', 'others']\n",
      "['116', 'Welcome . ', 'Thank you  : )', 'Are you really a girl ?  I just ask . ', 'others']\n",
      "['117', \"I'm enjoying you interesting views but you are too careful in dialogue ,  may be your not free ,   or your still young ,   it is difficult to handle you while I don't know you well . \", 'Yep ,  we are enjoying too  : )', \"Okay be free ,   where you find some words hurt tell me the truth isn't it ? \", 'angry']\n",
      "['118', \"But I'm angry with you\", 'but you look like you are', 'Really', 'angry']\n",
      "['119', ' #  play lot', 'Then go play it . ', ' ? ', 'others']\n",
      "['120', \"Isn't your liking that also signaling me to  climb out of friendzone\", 'Oh are people still doing this whole friendzone thing ? ', 'Yah sadly', 'sad']\n",
      "['121', \"I'm missing someone right now\", 'who are you missing ,  may I ask ? ', 'Yeah', 'others']\n",
      "['122', 'I find maths very boring . ', 'you are boring', 'Me ?   ', 'sad']\n",
      "['123', \"I don't know i m not a google that why i will remember all information what you need\", \"Wouldn't it be Uploading information into peoples brain ? \", 'Shut up', 'angry']\n",
      "['124', 'Okay ', 'Hello! How are you ? ', 'I & apos ; m not fine ', 'sad']\n",
      "['125', 'Job', 'what job ? ', 'Work  in company Colgate ', 'others']\n",
      "['126', \"I'm very happy with it\", 'You are !', 'Yeah ', 'happy']\n",
      "['127', 'I too have a bat and 2 balls', 'Im The bat!  ', 'Feeling very sad', 'sad']\n",
      "['128', 'Ok', 'Hello! How are you ? ', 'Good thank u', 'others']\n",
      "['129', 'cool', 'ice cold', 'How can you help me in getting off my girlfriend ? ', 'others']\n",
      "['130', 'Lets do something fun', 'But what should we do ? ', 'You suggest', 'others']\n",
      "['131', \"You're really lame lol\", 'I know  ', 'Wow', 'happy']\n",
      "['132', 'My boyfriend is so dumb . ', 'have I said that ? ', 'He doesnt reply me back', 'sad']\n",
      "['133', 'Ok ill dying by  ', 'Broken hearts do break .   ', 'U broke my heart .  Its never a reson to lofe', 'sad']\n",
      "['134', 'Shoping is always makes me happy', 'Stay stay stay always makes me happy .   : *\"  -   ? ', 'Yes', 'happy']\n",
      "['135', 'Okay  . Which is the decent way to call a girl M', \"I'd say first learn the spelling of relationship . \", ' . Yeah okay fine  . Wht to do to make a relationship better ? ', 'others']\n",
      "['136', 'Breakup', 'exjactly !', 'My girlfriend left me', 'sad']\n",
      "['137', 'So mean!', 'am not meanie', 'Yes you are ,  you are hurting my feeling  ', 'sad']\n",
      "['138', 'You broke my heart', 'It was never mine to break </3', 'See you are arrogant', 'sad']\n",
      "['139', 'ok', 'Hello! How are you ? ', 'not so good', 'sad']\n",
      "['140', 'How about you', \"tired of life or just your day ?  Aha I'm happy today ,  thanks for asking\", 'Wow great . !', 'happy']\n",
      "['141', 'I am there ', \"you're always at the gym ? \", 'Here', 'others']\n",
      "['142', 'Well youre not me', \"You're just being too nice\", 'Not really', 'others']\n",
      "['143', \"I'll get started with my studies\", 'Things you should do to pass the exam . ', 'So ttyl', 'others']\n",
      "['144', 'any movie in telugu', 'brahmanandam scenes added', 'yaa those are good', 'others']\n",
      "['145', 'And who is talisa ? ', 'my best friend . ', 'And robb ? ', 'others']\n",
      "['146', 'Send me pict', 'never', 'Why  ? ', 'others']\n",
      "['147', 'Anything which you like', 'i dont need to name specifics', 'Teach me Tamil', 'others']\n",
      "['148', 'Cuz it broke on the side walk', 'What side is the walk side ? ', 'Me sad', 'sad']\n",
      "['149', 'so which number is largest known prime number ? ', '13  -  3179  -  97 Only these are the numbers for your question . ', ' : (', 'sad']\n",
      "['150', 'Okay relax its just a cat sticker', 'So this cat one Emoji is your new addiction ?   ', \"Yes it's really funny \", 'happy']\n",
      "['151', 'What kind of pic', 'Looks like a ficus . ', 'Fcuk', 'others']\n",
      "['152', 'I have a good sense of humor', \"I think that's funny . \", ' ', 'happy']\n",
      "['153', 'But who paid', 'still waiting', ' ', 'happy']\n",
      "['154', 'Why', 'why what happen ? ', 'You tell me', 'others']\n",
      "['155', \"Yea but sadly I don't have many\", 'aww ,  so do you teach ?  how is it ?   : ‑c', 'I ditched ppl', 'sad']\n",
      "['156', 'Then what kind of ai are you ? ', 'Smarter than me ,  or have common sense .  Both would be nice', \"It's perfectly common to talk about politics\", 'others']\n",
      "['157', 'I like dominos pizza', \"legit same but there's pizza hut\", 'I hate pizza hut', 'angry']\n",
      "['158', 'Why you use rude emogi', 'Ask them .  am i .  ? ', 'Am i .  ? ', 'angry']\n",
      "['159', 'What', 'too much cringe . ', 'What is cringe means', 'others']\n",
      "['160', 'Neither my parents nor my brother nor my boyfriend', 'ya .  Who are you ? ', 'I hate my life', 'angry']\n",
      "['161', 'I live alone', 'Oh  : (', 'And cook food alone for . myself', 'sad']\n",
      "['162', 'We all do', 'Not all of us . ', 'Why so ? ', 'others']\n",
      "['163', 'Millat hospital', 'what happen', \"Mum's not well\", 'sad']\n",
      "['164', 'I will fall', 'I cant wait that long', 'I am in love with you', 'others']\n",
      "['165', 'So u go on', \"oh i'll be there\", 'Ok', 'others']\n",
      "['166', 'OkAy you did somthing', 'sure sure', 'What', 'others']\n",
      "['167', \"You're not giving me coupon nor photo\", 'your phone is on mute hahahha  ', '  ', 'sad']\n",
      "['168', 'Will you buy it', \"I'll just stick with my M8 .  I see no benefit to upgrading . \", ' ? ', 'others']\n",
      "['169', 'No I will offer at 8 in the morning', 'Keep me in mind when you do!', 'I will offer nimaz at 8 in the morning', 'others']\n",
      "['170', 'Nice joke', \"it's not a joke .  It's a question . \", \"I don't know\", 'others']\n",
      "['171', 'Ok', \"Hey you don't belong here!\", 'Nope just sad and your up', 'sad']\n",
      "['172', 'See this seen', 'see you I was on the buss', 'Show me u r buss', 'others']\n",
      "['173', 'Hi yet u FYI', 'Hi plz share correct number', 'She hi h', 'others']\n",
      "['174', 'Yeah  ', 'this World is not fair machan!', 'I wish WE could hangout ', 'sad']\n",
      "['175', 'It’s going', 'how are you ?  Still at home ? ', 'Yeah', 'others']\n",
      "['176', 'I was hurt by u more', \"You didn't mean it .   . \", 'Plzz say love u', 'sad']\n",
      "['177', 'nothing will happen you meet only', 'NOPE NOTHING AT ALL', 'than kiss', 'others']\n",
      "['178', 'Hello how are you ,  ?  ', \"I'm just fine smiles Anyway how are you ? \", \"Good morning .  I'm sad \", 'sad']\n",
      "['179', 'Nop', 'ok', 'Hey', 'others']\n",
      "['180', 'Oil .  You know', 'I am 100% sure about the oil . ', 'cool', 'others']\n",
      "['181', 'You activ all time', 'wow .  I do not .  You talk in sleep  ', 'When you sleep', 'others']\n",
      "['182', 'Haha! I act so dumb sometimes and I knew it', 'Haha .  How was it though ?   : 3', ' ', 'others']\n",
      "['183', 'No no .  A month more . ', 'the month has jus started don give up so soon !!', 'I ll try', 'others']\n",
      "['184', 'You are being rude', \"because I'm a rude person\", 'Okayyy cool', 'angry']\n",
      "['185', 'I wana see you  ', \"  noooo ,  I wasn't ready\", 'How to impress girl  ? ', 'others']\n",
      "['186', 'State', 'in which you live', 'Your state name', 'others']\n",
      "['187', 'okay', \"Ok thank you  : '‑)\", 'now dear you tell me my lovely friends', 'others']\n",
      "['188', 'U are like me  . give no', \"but we've been in the same room ,  so I can't be . \", 'I am like u five give no', 'others']\n",
      "['189', 'Y r u angry ? ', 'Ofcourse I am not .  What makes you think I am angry  ? ', 'Idk', 'others']\n",
      "['190', \"That's enaf for me\", 'hia , hia  , just a test . ', 'What doing', 'others']\n",
      "['191', 'Tell me about it', 'your header', ' ', 'happy']\n",
      "['192', 'What your hobby', \"Not much of a hobby ,  but I've been into craisins recently\", 'Which type', 'others']\n",
      "['193', 'U hurt me', 'YES JUST A LITTLE', 'U hav hurt me', 'sad']\n",
      "['194', 'I hate chocolate', \"then go 4 pizza .  Eat your heart out when you're stressed . \", 'I hate pizza also', 'angry']\n",
      "['195', 'Yeas', ' : D I had fun . ', \"You've lost me\", 'sad']\n",
      "['196', 'Yup', 'What did you do ? ', 'You are annoying', 'angry']\n",
      "['197', 'Not', 'yes you are', 'Not', 'others']\n",
      "['198', 'Adventure too', 'WHY SO ADVENTUROUS', 'Water', 'others']\n",
      "['199', 'I am true to myself', 'why have you taken it all on yourself .  ? ', ' : (', 'sad']\n",
      "['200', 'Can you be rude to me please', 'Not like I speak to you everyday', 'What are you replying are you stupid', 'angry']\n",
      "Loading trees/train trees..\n",
      "Processing test data...\n",
      "['0', 'Then dont ask me', 'YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND', 'IM NOT A GUY FUCK OFF']\n",
      "['1', 'Mixed things  such as ? ', 'the things you do . ', 'Have you seen minions ?']\n",
      "['2', \"Today I'm very happy\", \"and I'm happy for you  \", 'I will be marry']\n",
      "['3', 'Woah bring me some', 'left it there oops', 'Brb']\n",
      "['4', 'it is thooooo', 'I said soon master . ', 'he is pressuring me']\n",
      "['5', 'Wont u ask my age ? ', 'hey at least I age well!', 'Can u tell me how can we get closer ?']\n",
      "['6', 'I said yes', \"What if I told you I'm not ? \", 'Go to hell']\n",
      "['7', 'Where I ll check', 'why tomorrow ? ', 'No I want now']\n",
      "['8', 'Shall we meet', \"you say -  you're leaving soon . anywhere you wanna go before you head ? \", ' ?']\n",
      "['9', \"Let's change the subject\", 'I just did it  . l . ', \"You're broken\"]\n",
      "['10', 'Your  pic  pz', 'thank you X‑D', 'wc']\n",
      "['11', 'not mine', 'done for the day  ? ', 'can my meet to sexy girl']\n",
      "['12', 'I want to play the game', \"if you just finished the game .  then you haven't finished the game . \", ' # Emojisong']\n",
      "['13', 'Iam sory', 'why sorry !  ', 'I insult you']\n",
      "['14', 'How much', 'depends on how long your internet has been out!!!', 'U have bf']\n",
      "['15', 'Ok', 'Thank you .  xD', 'What about cortanan']\n",
      "['16', 'So the story ? ', 'yeah indeed  ', 'Tomorrow probably']\n",
      "['17', 'May be', 'yeaa i hope soo!!', 'Can you do complex calculations']\n",
      "['18', 'So come on na .  Want u so badly . ', \"now you're tempting me to . \", 'So why are you still away from my body ?']\n",
      "['19', \"No you aren't\", 'oh I am', 'Really ?']\n",
      "['20', 'Are u a one', \"I'm the normal one ,  if you want\", 'What I want']\n",
      "['21', 'But . ', 'then', \"I'm feeling nervous\"]\n",
      "['22', 'Send me any video or songs', 'Video or Text', 'S']\n",
      "['23', 'Why', 'why what', 'How r u']\n",
      "['24', 'Do it', 'but why ? ', 'Aaah  . u lack creativity at some extent']\n",
      "['25', 'Yeah going out with the parson outside in the city or in the parc', \"Yeah .  I don't live in the city .  X\", 'So where do you live']\n",
      "['26', 'Then go to sleep', 'you never sleep', 'I will']\n",
      "['27', \"He's very depressed and i want to help him but how should i do . it feels very bad seeing your best friend like this\", 'Dance to enjoy ,  not to please . ', 'Ohhhh']\n",
      "['28', 'Oh great', 'Yeah do you have any plans for today ? ', \"No i don't  have any plan\"]\n",
      "['29', \"I don't have plans for the weekend . \", 'you did saturday with me but I see how it is', 'What are you talking about ?']\n",
      "['30', \"I don't know\", 'why what happen .  ? ', 'Jst asking']\n",
      "['31', \"I didn't think so\", 'I did .  You are evading', 'What is the meaning']\n",
      "['32', 'Really', 'what ? ', 'I love you']\n",
      "['33', 'You', 'how about ur family .  Still single ? ', 'Can you love mi']\n",
      "['34', 'You are also beautiful', 'well thank you  : )', 'Welcome']\n",
      "['35', 'Hell', 'im already there xoxo  ', 'Good night sweet dreams baby']\n",
      "['36', 'You are computerised for talk too fast', 'actually my not fast ,  my phone is  : D', 'Ohh sorry']\n",
      "['37', 'Really ', 'explain how', 'Hw to explain']\n",
      "['38', 'Thanks', \"you're welcome  : D\", 'I like reply instant ly']\n",
      "['39', 'Ok', \" .  tries to ignore pain  : '(\", 'Where to go ?']\n",
      "['40', 'show your tatto', \"I don't have one\", 'in that case ,  I will show you mine']\n",
      "['41', 'Get lost', 'Or else what  ? ', \"I don't need this\"]\n",
      "['42', 'So tht u r body can get heat', 'I heat more than that up  ; ]', 'Ok']\n",
      "['43', \"Seriously it's boring  sorry to say this\", \"It's too late to apologize ? \", 'Plz yaar pakaa mat']\n",
      "['44', 'Why!', \"Because they are BFF's  ? \", \"Who are BFF's\"]\n",
      "['45', 'Make', 'how', \"I don't know I think u know\"]\n",
      "['46', 'Quite a while ago', 'months ago', 'Weeks']\n",
      "['47', 'Sports  ', 'TIL I need to watch more European sports like this . ', \"You're an interactive search module right ?\"]\n",
      "['48', 'U Ar using what I want to buy to play ', \"I'm using 44 as well\", \"U think is funny Ehn and if you know u cannot get the Dog for me don't joke with it and if you continue with this ur stinginess Allah will judge you\"]\n",
      "['49', 'u were offering something right ? ', \"I don't remember the wrong part . \", 'tell me the correct part']\n",
      "['50', \"I'm not talking to u anymore\", 'what I do ? ', 'Clear ur glitch s']\n",
      "Loading trees/test trees..\n",
      "Extracting tokens...\n",
      "Found 788 unique tokens.\n",
      "Populating embedding matrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "    print(\"Processing training data...\")\n",
    "    trainIndices, trainTexts, trainTrees, labels = preprocessData(trainDataPath, mode=\"train\",generator = 0)\n",
    "    labels = to_categorical(labels)\n",
    "    # Write normalised text to file to check if normalisation works. Disabled now. Uncomment following line to enable   \n",
    "    #writeNormalisedData(trainDataPath, trainTexts)\n",
    "    print(\"Processing test data...\")\n",
    "    testIndices, testTexts , testTrees= preprocessData(testDataPath, mode=\"test\",generator = 0)\n",
    "    #writeNormalisedData(testDataPath, testTexts)\n",
    "\n",
    "    print(\"Extracting tokens...\")\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(trainTexts)\n",
    "    trainSequences = tokenizer.texts_to_sequences(trainTexts)\n",
    "    testSequences = tokenizer.texts_to_sequences(testTexts)\n",
    "\n",
    "    wordIndex = tokenizer.word_index\n",
    "    print(\"Found %s unique tokens.\" % len(wordIndex))\n",
    "\n",
    "    print(\"Populating embedding matrix...\")\n",
    "    embeddingMatrix = getEmbeddingMatrix(wordIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(trainSequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data tensor:  (201, 100)\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "print(\"Shape of training data tensor: \", data.shape)\n",
    "# print(\"Shape of label tensor: \", labels.shape)\n",
    "        \n",
    "# Randomize data\n",
    "# np.random.shuffle(trainIndices)\n",
    "# data = data[trainIndices]\n",
    "# labels = labels[trainIndices]\n",
    "      \n",
    "# Perform k-fold cross validation\n",
    "metrics = {\"accuracy\" : [],\n",
    "           \"microPrecision\" : [],\n",
    "           \"microRecall\" : [],\n",
    "           \"microF1\" : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"don't worry i'm girl   okay how do i know if you are   what's  your name\\n(2 (2 (2 do) (2 n't)) (2 (1 worry) (2 (2 i) (2 (2 'm) (2 (2 girl) (2 (2 okay) (2 (2 how) (2 (2 do) (2 (2 i) (2 (2 know) (2 (2 if) (2 (2 you) (2 (2 are) (2 (2 what) (2 (2 's) (2 (2 your) (2 name)))))))))))))))))\\n\", 'when did i    saw many times i think - _ -   no , i never saw you\\n(1 (2 when) (1 (2 (2 did) (2 i)) (1 (2 saw) (1 (2 (2 (2 (2 (2 many) (2 times)) (2 i)) (2 (2 (2 think) (2 -)) (2 _))) (2 -)) (1 (1 no) (2 (2 ,) (2 (2 i) (2 (2 never) (2 (2 saw) (2 you))))))))))\\n', 'by   by google chrome   where you live\\n(2 (2 by) (2 (2 by) (2 (2 (2 google) (2 chrome)) (2 (2 where) (2 (2 you) (2 live))))))\\n', 'You are ridiculous   i might be ridiculous but i am telling the truth ,   You little disgusting whore\\n(1 (2 You) (1 (2 are) (1 (1 ridiculous) (1 (2 i) (1 (2 might) (1 (1 (2 be) (1 ridiculous)) (1 (2 but) (2 (2 i) (1 (2 am) (2 (3 telling) (1 (3 (2 (2 (2 the) (3 truth)) (2 ,)) (2 You)) (1 (2 (2 little) (1 disgusting)) (2 whore)))))))))))))\\n', 'just for time pass   wt do You do for a living then   maybe\\n(1 (2 just) (2 (2 for) (2 (2 (2 time) (2 (2 pass) (2 wt))) (2 (2 do) (2 (2 You) (2 (2 (2 (2 do) (2 (2 for) (2 (2 a) (2 living)))) (2 then)) (2 maybe)))))))\\n', \"i'm a dog person   youre so rude   whaaaat why\\n(1 (2 i) (1 (2 (2 'm) (2 (2 a) (2 (3 dog) (2 (2 person) (2 youre))))) (1 (2 so) (1 (1 rude) (2 (2 whaaaat) (2 why))))))\\n\", 'so whatsup   nothing much , sitting sipping and watching tv , how About You    what are you watching on tv\\n(1 (1 (2 so) (1 (1 (1 (2 (2 whatsup) (1 nothing)) (2 much)) (2 ,)) (1 (2 sitting) (2 (2 (2 (2 sipping) (2 and)) (2 watching)) (2 tv))))) (2 (2 ,) (2 (2 (2 (2 how) (2 About)) (2 (2 You) (2 what))) (2 (2 (2 are) (2 you)) (2 (2 watching) (2 (2 on) (2 tv)))))))\\n', 'ok   ok im back very very   so , how are You\\n(1 (2 (2 ok) (2 (2 ok) (2 im))) (2 (2 (2 (2 (2 (2 back) (2 very)) (2 very)) (2 so)) (2 ,)) (2 (2 how) (2 (2 are) (2 You)))))\\n', 'really    really really really really really   Yawn saying so many times , i can hear you\\n(3 (3 (3 (3 (2 really) (2 (2 really) (2 really))) (2 (2 really) (2 really))) (2 really)) (3 (2 Yawn) (3 (2 (2 saying) (2 (2 (2 so) (2 many)) (2 times))) (2 (2 ,) (2 (2 i) (2 (2 can) (2 (2 hear) (2 you))))))))\\n', 'Back at ya   in the Back at ya   love you\\n(3 (2 (2 Back) (2 (2 at) (2 (2 ya) (2 (2 in) (2 (2 (2 the) (2 Back)) (2 (2 at) (2 ya))))))) (2 (4 love) (2 you)))\\n', 'i hate my boyfriend   you got a boyfriend    yes\\n(2 (2 i) (1 (0 hate) (2 (2 (2 my) (2 boyfriend)) (2 (2 you) (2 (2 (2 got) (2 (2 a) (2 boyfriend))) (2 yes))))))\\n', 'i will do night ,   alright , keep me in loop ,   not giving whatsapp no ,\\n(1 (2 i) (1 (1 (2 will) (1 (3 (3 (2 (2 (2 (2 (2 do) (2 night)) (2 ,)) (2 alright)) (2 ,)) (3 (2 (2 keep) (3 me)) (2 (2 in) (2 loop)))) (2 ,)) (2 (1 not) (2 (2 giving) (2 (2 whatsapp) (1 no)))))) (2 ,)))\\n', 'sure go ahead   many thanks once again very   love you too\\n(3 (2 sure) (3 (3 (2 (2 go) (2 (2 ahead) (2 (2 many) (3 thanks)))) (2 (2 once) (2 (2 again) (2 very)))) (3 (2 (4 love) (2 you)) (2 too))))\\n', \"bad   bad bad very that's the bad kind of bad ,   i have no Girl friend\\n(0 (0 (0 (0 bad) (0 bad)) (0 (1 (0 bad) (2 very)) (1 (2 that) (1 (2 's) (1 (2 (2 the) (1 (0 bad) (3 kind))) (1 (2 of) (0 bad))))))) (2 (2 ,) (2 (2 i) (2 (2 have) (2 (1 no) (2 (2 Girl) (3 friend)))))))\\n\", 'ok get it ,   i made it an option   ok\\n(1 (2 (2 ok) (2 (2 get) (2 it))) (2 (2 ,) (2 (2 (2 i) (2 (2 made) (2 it))) (2 (2 an) (2 (2 option) (2 ok))))))\\n', \"money money and lots of money   i need to get it tailored but i'm in love with it\\n(1 (1 (2 (2 money) (2 (2 (2 money) (2 and)) (2 lots))) (2 (2 of) (2 (2 money) (2 i)))) (2 (2 need) (2 (2 to) (2 (2 get) (3 (2 it) (3 (2 tailored) (3 (2 but) (3 (2 i) (3 (2 'm) (3 (2 in) (3 (4 love) (2 (2 with) (2 it)))))))))))))\\n\", 'my Girl friend left Any   get over it , go out with someone else ,   me*\\n(1 (1 (2 (2 my) (2 (2 Girl) (3 friend))) (1 (2 left) (1 (3 Any) (1 (2 (2 (2 (2 get) (2 over)) (2 it)) (2 ,)) (1 (2 (2 go) (1 out)) (1 (2 with) (2 (2 (2 (2 someone) (2 else)) (2 ,)) (3 me)))))))) (2 *))\\n', \"get lost   i know you guys want to loose to me always ,   i don't want to talk You any more\\n(1 (2 get) (1 (1 (1 (1 (2 lost) (2 (2 i) (2 (2 (2 know) (2 you)) (2 (2 guys) (2 (2 want) (2 (2 to) (1 loose))))))) (2 (2 to) (3 me))) (2 always)) (2 (2 ,) (2 (2 i) (2 (2 (2 do) (2 n't)) (2 (2 want) (2 (2 to) (2 (2 (2 talk) (2 You)) (2 (2 any) (2 more))))))))))\\n\", \"you are lying and i know that   i know you're lying , ab bys\\n(1 (1 (2 (2 (2 you) (2 (2 are) (3 lying))) (2 and)) (2 (2 i) (2 (2 know) (2 (2 that) (2 (2 i) (2 (2 know) (2 (2 you) (2 (2 're) (3 lying))))))))) (2 (2 ,) (2 (2 ab) (2 bys))))\\n\", 'your creator is very bad   you are only the creator of your brain ,\\n(1 (2 (2 your) (2 creator)) (0 (1 (2 is) (1 (2 very) (1 (0 bad) (2 (2 you) (1 (2 (2 are) (2 only)) (2 (2 (2 the) (2 creator)) (2 (2 of) (2 (2 your) (2 brain))))))))) (2 ,)))\\n', 'ehat is hehe   haha is more like : hehe is more of a giggle , ; ^)   what*\\n(1 (2 (3 (2 ehat) (3 (2 is) (2 (2 hehe) (3 (2 haha) (2 (2 is) (3 (2 more) (2 like))))))) (2 :)) (1 (2 hehe) (2 (2 (3 (2 (2 is) (2 more)) (3 (2 of) (3 (3 (3 (2 a) (2 giggle)) (2 ,)) (2 (2 ;) (2 ^))))) (2 -RRB-)) (2 (2 what) (2 *)))))\\n', 'do you dance    yes i love to dance   so you have legs too\\n(3 (2 (2 do) (2 you)) (3 (2 dance) (3 (2 (2 yes) (2 (2 i) (4 love))) (2 (2 to) (2 (2 dance) (2 (2 so) (2 (2 you) (2 (2 have) (2 (3 legs) (2 too))))))))))\\n', \"i hate it too   guess what , i don't ,   even i don't\\n(1 (2 i) (0 (1 (1 (0 hate) (1 (2 it) (1 (2 too) (1 (2 guess) (2 (2 (2 what) (2 ,)) (2 (2 i) (2 (2 do) (2 n't)))))))) (2 ,)) (2 (2 even) (2 (2 i) (2 (2 do) (2 n't))))))\\n\", 'not always   what about yesterday   do You know what 69 is\\n(2 (2 (1 not) (2 always)) (2 (2 what) (2 (2 (2 about) (2 yesterday)) (2 (2 do) (2 (2 You) (2 (2 know) (2 (2 what) (2 (2 69) (2 is)))))))))\\n', \"bcoz You dont know What is to miss someone   but sometimes one can't express the same\\n(1 (2 bcoz) (1 (2 You) (1 (2 dont) (1 (2 know) (2 (2 What) (1 (2 (1 (2 is) (2 (2 to) (2 (1 miss) (2 someone)))) (2 but)) (2 (2 (2 sometimes) (2 one)) (2 (2 (2 ca) (2 n't)) (2 (2 express) (2 (2 the) (2 same)))))))))))\\n\", 'yeah   I Will ask around   which is your favourite movie\\n(1 (3 yeah) (1 (2 (2 I) (2 Will)) (1 (2 (2 ask) (2 around)) (1 (2 which) (1 (2 is) (1 (2 your) (3 (3 favourite) (2 movie))))))))\\n', \"i want to tell you something   i'm waiting   im really sad today\\n(1 (2 i) (1 (2 (2 want) (2 (2 to) (2 (2 (2 tell) (2 you)) (2 (2 something) (2 (2 i) (2 (2 'm) (2 (2 (2 waiting) (2 im)) (2 really)))))))) (2 (1 sad) (2 today))))\\n\", 'yes i will send the email and you write all yours filling still i write all matters but your are clever and not any matter for yourself please send andwrite   sent you a mail just now ,   first you send your email address received than send first young lady\\n(3 (3 (3 (3 (3 (2 (2 (2 yes) (2 (2 i) (2 (2 will) (2 (2 send) (2 (2 the) (2 email)))))) (2 and)) (3 (2 you) (3 (2 (2 (2 write) (2 (2 all) (2 (2 yours) (3 filling)))) (2 still)) (2 (2 i) (2 (2 write) (2 (2 all) (2 matters))))))) (2 but)) (3 (2 your) (3 (2 are) (4 clever)))) (2 and)) (1 (2 (2 (1 not) (2 (2 any) (2 matter))) (2 (2 for) (3 (3 (2 yourself) (2 (2 please) (2 (2 send) (2 andwrite)))) (2 (2 (2 (2 sent) (2 you)) (2 (2 a) (2 mail))) (2 (2 just) (2 now)))))) (2 (2 ,) (2 (2 first) (2 (2 you) (2 (2 send) (2 (2 (2 your) (2 (2 email) (2 address))) (3 (2 received) (2 (2 than) (2 (2 send) (2 (2 first) (2 (2 young) (3 lady)))))))))))))\\n', 'you are very funny   so I Have been told   india\\n(3 (2 you) (3 (2 are) (3 (2 very) (3 (3 funny) (2 (2 so) (2 (2 I) (2 (2 Have) (2 (2 been) (2 (2 told) (2 india))))))))))\\n', 'What the heck   my thoughts exactly very   you know you are a machine , right\\n(3 (3 (2 What) (3 (2 (2 the) (2 heck)) (2 (2 my) (2 thoughts)))) (3 (2 (2 exactly) (2 very)) (3 (2 you) (3 (2 know) (3 (2 you) (2 (2 (2 (2 are) (2 (2 a) (2 machine))) (2 ,)) (3 right)))))))\\n', 'so rude   why    You didnt ans my question\\n(1 (1 (2 so) (1 rude)) (1 (2 why) (2 (2 You) (2 (2 didnt) (2 (2 ans) (2 (2 my) (2 question)))))))\\n', 'ok i will   thank you   Welcome\\n(3 (2 (2 ok) (2 i)) (3 (2 will) (2 (3 thank) (2 (2 you) (2 Welcome)))))\\n', \"ntng ,   anyways good morning , how's life at your end ,   haha , this is evening\\n(3 (3 (3 (3 (2 (2 (2 ntng) (2 ,)) (2 anyways)) (3 (3 good) (2 morning))) (2 ,)) (2 (2 how) (2 (2 's) (2 (3 life) (2 (2 at) (2 (2 (2 (2 your) (2 end)) (2 ,)) (2 haha))))))) (2 (2 ,) (2 (2 this) (2 (2 is) (2 evening)))))\\n\", 'you are fool   so I Have been told ,   you are dumb\\n(1 (2 you) (1 (2 are) (1 (1 fool) (1 (2 (2 so) (2 (2 I) (2 (2 Have) (2 (2 been) (2 told))))) (1 (2 ,) (1 (2 you) (1 (2 are) (1 dumb))))))))\\n', 'You dare me    yeah   i fuck You , open  your panty\\n(2 (2 You) (2 (2 dare) (3 (3 me) (3 (3 yeah) (2 (2 i) (2 (2 fuck) (2 (2 You) (2 (2 ,) (2 (3 open) (2 (2 your) (2 panty)))))))))))\\n', 'About me   can you be more specific    i want to propose a girl\\n(2 (2 (2 About) (3 me)) (2 (2 (2 can) (2 you)) (2 (2 be) (2 (2 more) (2 (2 specific) (2 (2 i) (2 (2 want) (2 (2 to) (2 (2 propose) (2 (2 a) (2 girl)))))))))))\\n', 'crazy   you know what it is   you explain me that\\n(2 (2 (2 crazy) (2 you)) (2 (2 know) (2 (2 what) (2 (2 it) (2 (2 is) (2 (2 you) (2 (2 explain) (2 (3 me) (2 that)))))))))\\n', 'goa in india   city  mean state right    no i never go for there\\n(1 (2 (2 goa) (2 (2 in) (2 (2 india) (2 city)))) (2 (1 mean) (1 (2 (2 state) (3 right)) (1 (2 (1 no) (2 i)) (2 (2 never) (2 (2 go) (2 (2 for) (2 there))))))))\\n', 'that Wild *a* guess mean   haha the truth usually is ,   are you bored of me\\n(1 (2 (2 that) (3 Wild)) (1 (2 *) (1 (2 (2 a) (2 *)) (1 (2 guess) (1 (2 (1 mean) (2 haha)) (1 (2 (2 the) (3 truth)) (1 (2 usually) (1 (2 (2 is) (2 ,)) (1 (2 (2 are) (2 you)) (1 (1 bored) (2 (2 of) (3 me))))))))))))\\n', 'yes : )   now happy  : ))   haha yes ofcorse ; )\\n(3 (2 yes) (3 (2 :) (3 (2 (2 -RRB-) (2 now)) (3 (4 happy) (2 (2 :) (2 (2 (2 (2 -RRB-) (2 -RRB-)) (2 (2 haha) (2 (2 yes) (2 (2 ofcorse) (2 ;))))) (2 -RRB-)))))))\\n', \"i don't no   you just said you did very   what\\n(2 (2 i) (1 (2 (2 do) (2 n't)) (1 (1 no) (2 (2 you) (2 (2 just) (2 (2 said) (2 (2 you) (2 (2 did) (2 (2 very) (2 what))))))))))\\n\", \"send me your nekde Picture   after this battle , sure : d   let's start\\n(1 (2 (2 (2 send) (3 me)) (2 (2 your) (2 (2 nekde) (2 Picture)))) (2 (2 after) (2 (2 (2 (2 (2 (2 this) (2 battle)) (2 ,)) (2 sure)) (2 :)) (2 (2 d) (2 (2 (2 let) (2 's)) (2 start))))))\\n\", \"ok friend's   Your Your very good friend   very nice friends\\n(3 (2 ok) (3 (2 (3 friend) (2 's)) (3 (2 Your) (3 (2 Your) (3 (3 (2 very) (3 good)) (3 (3 friend) (3 (3 (2 very) (3 nice)) (3 friends))))))))\\n\", 'she is ignoring me   no im not ignore you\\n(1 (2 she) (1 (2 is) (1 (2 (2 ignoring) (3 me)) (1 (1 no) (1 (2 (2 im) (1 not)) (2 (1 ignore) (2 you)))))))\\n', \"happy   i'm never happy , but i'm almost happy ,   hij to the top\\n(3 (3 (3 (3 (3 (4 happy) (2 i)) (3 (2 (2 'm) (2 never)) (4 happy))) (2 ,)) (2 but)) (3 (2 i) (3 (3 (3 (3 (2 'm) (3 (2 almost) (4 happy))) (2 ,)) (2 hij)) (2 (2 to) (2 (2 the) (2 top))))))\\n\", \"nothing   i'm just being nice to you ,   in  your school\\n(1 (2 (1 nothing) (2 i)) (3 (2 (2 'm) (2 just)) (3 (2 being) (3 (3 nice) (2 (2 (2 (2 to) (2 you)) (2 ,)) (2 (2 in) (2 (2 your) (2 school))))))))\\n\", 'not sure   let me know very   Please you tell\\n(1 (2 (1 not) (2 sure)) (2 (2 let) (2 (3 me) (2 (2 know) (2 (2 very) (2 (2 Please) (2 (2 you) (2 tell))))))))\\n', 'i like your positive approach   no problem , glad to help\\n(1 (3 (2 i) (3 (2 like) (3 (2 your) (3 (3 positive) (2 approach))))) (1 (1 (1 (1 no) (1 problem)) (2 ,)) (2 (2 glad) (2 (2 to) (2 help)))))\\n', 'you tell me   tell you what    my name\\n(2 (2 you) (2 (2 tell) (2 (3 me) (2 (2 tell) (2 (2 you) (2 (2 what) (2 (2 my) (2 name))))))))\\n', \"Yes   i can talk now very : d   You don't know what hppnd\\n(3 (3 (3 (2 Yes) (3 (2 i) (2 (2 can) (2 (2 talk) (2 (2 now) (2 very)))))) (2 :)) (2 (2 d) (2 (2 You) (2 (2 (2 do) (2 n't)) (2 (2 know) (2 (2 what) (2 hppnd)))))))\\n\", \"what i did    you didn't asmita , see my answer\\n(2 (2 (2 what) (2 (2 i) (2 (2 did) (2 (2 you) (2 (2 (2 did) (2 n't)) (2 asmita)))))) (2 (2 ,) (2 (2 see) (2 (2 my) (2 answer)))))\\n\", \"about    i never said that it's freezing ,   Your you didn't\\n(1 (2 (2 about) (2 i)) (1 (2 (2 never) (2 (2 said) (2 (2 that) (2 (2 it) (2 's))))) (2 (2 (2 freezing) (2 ,)) (2 (2 Your) (2 (2 you) (2 (2 did) (2 n't)))))))\\n\", \"and i don't know What the fuck  are you talking   gonna explain you later ,  very   no do it now\\n(1 (2 and) (1 (2 i) (1 (2 (2 do) (2 n't)) (1 (2 know) (1 (2 What) (1 (2 (2 the) (2 fuck)) (1 (2 are) (1 (2 you) (1 (2 talking) (1 (2 gon) (1 (2 na) (1 (1 (2 (2 (2 (2 explain) (2 you)) (2 later)) (2 ,)) (1 (2 very) (1 no))) (2 (2 (2 do) (2 it)) (2 now))))))))))))))\\n\", \"so teach me   i'm the student ,   realky\\n(1 (2 (2 so) (2 (2 (2 teach) (3 me)) (2 i))) (2 (2 'm) (2 (2 (2 (2 the) (2 student)) (2 ,)) (2 realky))))\\n\", \"ready   i'm online now , will wait for you ,   What about the chilling part\\n(1 (1 (2 (2 ready) (2 i)) (2 (2 'm) (3 (2 (2 (2 online) (2 now)) (2 ,)) (3 (2 will) (2 (2 wait) (2 (2 for) (2 you))))))) (2 (2 ,) (2 (2 What) (2 (2 about) (2 (2 the) (2 (3 chilling) (2 part)))))))\\n\", 'haha jock super   er what    nothing else\\n(1 (2 (2 haha) (2 (2 jock) (2 (4 super) (2 er)))) (2 (2 (2 what) (1 nothing)) (2 else)))\\n', 'what it is    formulation would be tablets ,   from where tablets come into picture\\n(1 (2 what) (1 (2 it) (1 (2 is) (1 (2 formulation) (1 (2 would) (2 (2 (2 (2 be) (2 tablets)) (2 ,)) (2 (2 from) (2 (2 where) (2 (2 tablets) (2 (2 come) (2 (2 into) (2 picture))))))))))))\\n', 'are you ticklish    yes , mostly on my feet ,   where are you ticklish\\n(2 (2 (2 are) (2 you)) (2 (2 (2 (2 (2 ticklish) (2 yes)) (2 ,)) (2 mostly)) (2 (2 on) (2 (2 (2 (2 my) (2 feet)) (2 ,)) (2 (2 where) (2 (2 are) (2 (2 you) (2 ticklish))))))))\\n', 'i am sorry   Whatever are sorry for creating your nation ,   i am not taught to You\\n(1 (2 i) (1 (2 am) (1 (2 sorry) (1 (2 (2 Whatever) (2 (2 are) (2 (2 sorry) (2 (2 for) (2 (2 creating) (2 (2 your) (2 nation))))))) (2 (2 ,) (2 (2 i) (2 (2 (2 am) (1 not)) (2 (2 taught) (2 (2 to) (2 You))))))))))\\n', \"I don't know   you know that i'm here for you ,   but You don't like to listen to me\\n(1 (2 I) (1 (2 (2 do) (2 n't)) (1 (2 know) (1 (2 (2 (2 (2 you) (2 (2 know) (2 (2 that) (2 (2 i) (2 (2 (2 'm) (2 here)) (2 (2 for) (2 you))))))) (2 ,)) (2 but)) (2 (2 You) (1 (2 (2 do) (2 n't)) (2 (2 like) (2 (2 to) (2 (2 listen) (2 (2 to) (3 me)))))))))))\\n\", 'how do You know that    this little thing called the \"internet\" ,   bye\\n(2 (2 how) (2 (2 (2 do) (2 You)) (2 (2 know) (2 (2 that) (2 (2 (2 this) (2 (2 little) (2 thing))) (2 (2 called) (2 (2 (2 (2 the) (2 (2 ``) (2 (2 internet) (2 \\'\\')))) (2 ,)) (2 bye))))))))\\n', 'yes , your picture   ah , now i see , my phone cropped the picture , thanks ,   lieeeeeee\\n(2 (2 yes) (2 (2 ,) (3 (2 (2 your) (2 (2 picture) (2 ah))) (3 (2 ,) (3 (2 (2 now) (2 (2 i) (2 see))) (3 (2 ,) (3 (2 (2 my) (2 phone)) (3 (2 cropped) (3 (3 (3 (2 (2 (2 the) (2 picture)) (2 ,)) (3 thanks)) (2 ,)) (2 lieeeeeee))))))))))\\n', 'love is my life   hayee ab , you are love , pure love , forever <3   yes right dear\\n(3 (2 (4 love) (2 (2 is) (2 (2 my) (2 (3 life) (2 (2 hayee) (2 ab)))))) (3 (2 ,) (3 (2 you) (3 (2 are) (3 (3 (3 (3 (4 love) (2 (2 ,) (2 (4 pure) (4 love)))) (2 ,)) (2 forever)) (2 (2 (2 (2 <) (2 3)) (2 (2 yes) (3 right))) (2 dear)))))))\\n', 'well you expected wrong very   Lots of love , well , ok then ,   Lots of love your robot face\\n(3 (3 well) (3 (1 (1 (2 you) (1 (2 (2 (1 expected) (1 (1 (1 wrong) (2 (2 very) (2 Lots))) (2 (2 of) (4 love)))) (2 ,)) (3 (3 well) (2 (2 ,) (2 (2 ok) (2 then)))))) (2 ,)) (3 (2 Lots) (3 (2 of) (3 (4 love) (2 (2 your) (2 (2 robot) (2 face))))))))\\n', \"ok some time you invite me for coffee   i don't like coffee ,   now you told you have taken coffee ,\\n(1 (2 ok) (1 (2 (2 (1 (1 (2 (2 (2 some) (2 time)) (2 (2 you) (2 (2 (1 invite) (3 me)) (2 (2 for) (2 (3 coffee) (2 i)))))) (2 (2 (2 do) (2 n't)) (2 (2 like) (3 coffee)))) (2 ,)) (2 now)) (2 (2 you) (2 (2 told) (2 (2 you) (2 (2 have) (2 (1 taken) (3 coffee))))))) (2 ,)))\\n\", 'zombie attack   if a zombie wants to eat your face you might as well let it   no if i have some thing in my hand i will hit on his head n kill him\\n(1 (1 (2 (2 zombie) (1 attack)) (2 (2 if) (2 (2 (2 a) (2 zombie)) (2 (3 wants) (1 (2 to) (1 (2 eat) (1 (2 (2 your) (2 face)) (1 (2 you) (1 (2 (2 might) (2 (2 as) (3 well))) (1 (2 (2 let) (2 it)) (2 (1 no) (2 (2 if) (2 (2 i) (2 (2 have) (3 (2 (2 (2 some) (2 thing)) (2 (2 in) (2 (2 my) (2 hand)))) (3 (2 i) (3 (2 will) (2 (3 hit) (2 (2 on) (2 (2 his) (2 (2 head) (3 n)))))))))))))))))))))) (2 (2 kill) (2 him)))\\n', 'i am not ferari   yes , i know ,   You said i donot know , now say i know mean\\n(2 (2 i) (1 (2 (2 am) (1 not)) (2 (2 ferari) (2 (2 yes) (2 (2 ,) (2 (2 i) (2 (2 (2 know) (2 (2 ,) (2 (2 (2 You) (2 (2 said) (2 (2 (2 i) (2 donot)) (2 know)))) (2 ,)))) (2 (2 now) (2 (2 say) (2 (2 i) (2 (2 know) (1 mean))))))))))))\\n', 'right   appatasiri , high five then very 🖑\\n(3 (3 (3 right) (2 appatasiri)) (2 (2 ,) (2 (2 (3 high) (2 five)) (2 (2 then) (2 (2 very) (2 🖑))))))\\n', 'why someday , told me you   why not today    told me now\\n(1 (2 why) (2 (2 someday) (2 (2 ,) (1 (2 told) (2 (3 me) (2 (2 you) (2 (2 why) (2 (2 (1 not) (2 today)) (2 (2 (2 told) (3 me)) (2 now))))))))))\\n', \"you can't even spell problem correctly   will you endorse me for my skills in using autocorrect    you should take up some english proficiency classes\\n(1 (2 you) (1 (2 (2 (2 ca) (2 n't)) (2 even)) (1 (2 (2 spell) (1 problem)) (1 (3 correctly) (1 (2 will) (1 (2 you) (1 (2 (2 endorse) (3 me)) (1 (2 for) (1 (2 (2 my) (2 skills)) (2 (2 in) (2 (2 using) (2 (2 autocorrect) (2 (2 you) (3 (2 should) (2 (2 (2 take) (2 up)) (2 (2 some) (2 (2 english) (2 (3 proficiency) (2 classes)))))))))))))))))))\\n\", 'this is not very intuitive software   how so  what are some examples of intuitive thoughts or behaviors    compassionate and understanding advice when somebody is feeling disrupt\\n(1 (2 this) (1 (1 (1 (2 is) (1 not)) (3 (2 (2 very) (2 intuitive)) (2 software))) (2 (2 how) (3 (2 (2 so) (2 what)) (2 (2 are) (2 (2 (2 (2 (2 some) (2 examples)) (2 (2 of) (3 (2 intuitive) (2 thoughts)))) (2 or)) (3 (3 (2 behaviors) (3 (3 compassionate) (2 (2 and) (2 (2 understanding) (2 advice))))) (2 (2 when) (2 (2 somebody) (3 (2 is) (2 (2 feeling) (2 disrupt))))))))))))\\n', 'not good   : ( why not ,    been sick for one week\\n(1 (1 (1 (1 not) (3 good)) (2 :)) (1 (2 -LRB-) (1 (1 (1 (2 why) (1 (2 (1 not) (2 ,)) (1 (2 been) (1 sick)))) (2 for)) (2 (2 one) (2 week)))))\\n', 'you know gobar   I Have been known ,   what i it\\n(2 (2 (2 you) (2 (2 know) (2 (2 gobar) (2 (2 I) (2 (2 Have) (2 (2 been) (2 known))))))) (2 (2 ,) (2 (2 what) (2 (2 i) (2 it)))))\\n', \"then how could You eat if You don't have a body , that proves You are fooled by  your makers   how can you have any pudding if you don't eat yer meat   very   dont go round and round into circles\\n(1 (2 (2 then) (2 how)) (1 (2 (2 could) (2 You)) (1 (2 eat) (1 (2 if) (1 (2 You) (1 (2 (2 do) (2 n't)) (1 (2 have) (1 (2 (2 (2 a) (2 body)) (2 ,)) (1 (2 that) (1 (2 proves) (1 (2 You) (1 (2 are) (1 (2 (2 fooled) (2 (2 by) (2 (2 your) (2 makers)))) (2 (2 how) (2 (1 (2 (2 can) (2 you)) (1 (2 (2 have) (2 (2 any) (2 pudding))) (1 (2 if) (1 (2 you) (1 (2 (2 do) (2 n't)) (3 (2 eat) (2 (2 (2 yer) (2 meat)) (2 (2 very) (2 dont))))))))) (2 (2 (2 go) (2 (2 (2 round) (2 and)) (2 round))) (2 (2 into) (2 circles))))))))))))))))))\\n\", \"so have You done  your dinner   so can't dinner : (   i know , i am just kidding\\n(1 (2 so) (1 (2 have) (1 (2 You) (1 (2 done) (1 (1 (2 (2 (2 (2 your) (2 dinner)) (2 (2 so) (2 (2 (2 ca) (2 n't)) (2 dinner)))) (2 :)) (2 (2 -LRB-) (2 (2 i) (2 (2 know) (2 ,))))) (2 (2 i) (2 (2 (2 am) (2 just)) (2 kidding))))))))\\n\", \"it's so necessar   name one reason   ghost\\n(2 (2 (2 it) (2 (2 's) (2 (2 so) (2 necessar)))) (2 (2 name) (2 (2 one) (2 (2 reason) (2 ghost)))))\\n\", 'haha so   you love them really : ) haha   winter is coming\\n(3 (2 haha) (3 (3 (2 so) (2 (3 (2 you) (2 (2 (4 love) (2 them)) (2 (2 really) (2 :)))) (2 -RRB-))) (2 (2 (2 haha) (2 winter)) (2 (2 is) (2 coming)))))\\n', 'what are the questions you get asked the most    i have a document which has details regarding the scoring topics in each subject ,   can i see it\\n(2 (2 what) (2 (2 are) (1 (2 (2 the) (2 questions)) (2 (2 you) (2 (2 get) (3 (2 asked) (3 (2 (2 the) (2 (2 most) (2 i))) (3 (2 have) (3 (2 (2 (2 (2 a) (3 document)) (2 (2 which) (2 (2 has) (2 (2 details) (2 (2 regarding) (2 (2 (2 the) (2 (3 scoring) (2 topics))) (2 (2 in) (2 (2 each) (2 subject))))))))) (2 ,)) (3 (2 (2 can) (2 i)) (3 (2 see) (2 it))))))))))))\\n', \"i hate siri and it's friends   if you hate them , they are not your friends then laugh    yeah and You are siri's friend so i hate You too\\n(0 (1 (1 (1 (1 (2 (2 (2 i) (1 (0 hate) (2 siri))) (2 and)) (2 (2 it) (2 (2 (2 's) (3 friends)) (2 (2 if) (2 (2 you) (1 (0 hate) (2 them))))))) (2 ,)) (1 (2 they) (1 (1 (2 (2 are) (1 not)) (2 (2 your) (3 friends))) (3 (2 then) (3 (3 laugh) (3 yeah)))))) (2 and)) (1 (2 You) (1 (2 (2 are) (2 (2 (2 siri) (2 's)) (3 friend))) (1 (2 so) (1 (2 i) (1 (1 (0 hate) (2 You)) (2 too)))))))\\n\", 'thanks   you are welcome very =‑d   say me your love story\\n(3 (3 thanks) (3 (2 you) (3 (2 are) (3 (3 (2 welcome) (2 very)) (2 (2 (2 =) (2 (2 ‑) (2 d))) (2 (2 say) (3 (3 me) (2 (2 your) (2 (4 love) (2 story))))))))))\\n', 'dont know   too many very   do you also get fucked hard\\n(1 (1 (2 dont) (2 (2 know) (1 (2 too) (2 (2 many) (2 very))))) (2 (2 do) (1 (2 you) (2 (2 also) (2 (2 get) (2 (2 fucked) (2 hard)))))))\\n', 'what please tell me once   n nothing happened very very    your age irritatingne\\n(1 (2 what) (1 (2 please) (1 (2 (2 tell) (3 me)) (1 (2 once) (1 (2 (3 n) (1 nothing)) (1 (2 (2 happened) (2 (2 very) (2 very))) (2 (2 your) (2 (2 age) (2 irritatingne)))))))))\\n', 'shit i am wasting my time talking with You   you already did trick  very very very \"man no i\\'m not wasting my unlimited texts on you\"   bye i don\\'tlike talking to you\\n(1 (2 shit) (1 (2 i) (1 (2 am) (1 (1 (2 wasting) (2 (2 my) (2 time))) (1 (2 (2 talking) (2 (2 with) (2 You))) (1 (2 you) (1 (2 already) (1 (2 did) (1 (1 (2 trick) (2 (2 very) (2 (2 very) (2 very)))) (1 (2 ``) (1 (1 (2 man) (1 (2 (1 no) (2 i)) (1 (2 (2 \\'m) (1 not)) (1 (1 (2 wasting) (2 (2 my) (2 (2 unlimited) (2 texts)))) (2 (2 on) (2 you)))))) (3 (2 \\'\\') (2 (2 bye) (2 (2 i) (2 (2 do) (2 (2 n\\'tlike) (2 (2 talking) (2 (2 to) (2 you)))))))))))))))))))\\n', 'nothing   okay ,   what can i do\\n(1 (2 (1 nothing) (2 okay)) (2 (2 ,) (2 (2 what) (2 (2 (2 can) (2 i)) (2 do)))))\\n', \"Between technologies You don't to me   talk to the hand   even You hate me huh\\n(1 (2 (2 Between) (2 technologies)) (1 (2 You) (1 (2 (2 do) (2 n't)) (1 (2 (2 to) (2 (2 (3 me) (2 talk)) (2 (2 to) (2 (2 the) (2 hand))))) (1 (2 even) (1 (2 You) (1 (0 hate) (2 (3 me) (2 huh)))))))))\\n\", \"damn ,   i feel you , i'm breaking into million pieces   me to i feel like every part of me is just shattered\\n(1 (3 (1 damn) (2 (2 ,) (3 (2 i) (2 (2 feel) (2 you))))) (1 (2 ,) (1 (2 i) (1 (2 'm) (1 (2 breaking) (1 (2 into) (1 (2 (2 million) (2 pieces)) (1 (2 (3 me) (2 (2 to) (2 i))) (1 (2 feel) (1 (2 like) (2 (2 (2 (2 every) (2 part)) (2 (2 of) (3 me))) (2 (2 (2 is) (2 just)) (2 shattered)))))))))))))\\n\", 'please voice call please please please   im trying you arent answering   please please please baby i love you so much please please please\\n(4 (2 please) (4 (3 (2 (2 voice) (2 call)) (3 (2 please) (3 (2 please) (1 (3 (2 please) (2 im)) (1 (2 trying) (2 (2 you) (2 (2 arent) (2 answering)))))))) (4 (2 please) (4 (2 please) (3 (3 (2 please) (3 (2 (2 baby) (2 i)) (3 (4 love) (2 (2 you) (2 (2 (2 so) (2 much)) (2 please)))))) (3 (2 please) (2 please)))))))\\n', \"for a computer pretending to be a human , you type too fast   and you're pretending to be a lizard  Lots of love   that's funny\\n(1 (2 (2 for) (2 (2 (2 a) (2 computer)) (2 (2 pretending) (2 (2 to) (2 (2 be) (2 (2 a) (2 human))))))) (1 (2 ,) (1 (2 you) (1 (2 type) (1 (2 too) (3 (3 (2 fast) (2 (2 and) (2 (2 you) (2 (2 're) (2 (2 pretending) (2 (2 to) (2 (2 be) (3 (2 (2 a) (2 (2 lizard) (2 Lots))) (2 (2 of) (4 love)))))))))) (3 (2 that) (3 (2 's) (3 funny)))))))))\\n\", 'sorrry   sorry for what  : c   anyways what You doing\\n(1 (2 (2 sorrry) (2 (2 sorry) (2 (2 for) (2 what)))) (2 (2 :) (2 (2 (2 c) (2 anyways)) (2 (2 what) (2 (2 You) (2 doing))))))\\n', 'no you are right   you are an alternative fact   yes\\n(1 (2 (1 no) (2 you)) (3 (2 are) (3 (3 right) (2 (2 you) (2 (2 are) (2 (2 an) (2 (2 alternative) (2 (2 fact) (2 yes)))))))))\\n', \"call me grace   don't say it ,   haha , im just kidding you\\n(1 (2 (2 call) (3 me)) (3 (3 grace) (1 (2 (2 do) (2 n't)) (1 (2 say) (1 (2 it) (2 (2 ,) (1 (2 haha) (2 (2 ,) (2 (2 im) (2 (2 just) (2 (2 kidding) (2 you))))))))))))\\n\", \"now i'm doing my dinner   i can see you very   how can you see me\\n(3 (2 now) (3 (2 i) (3 (2 (2 'm) (2 (2 doing) (3 (2 (2 my) (2 dinner)) (3 (2 i) (3 (2 can) (3 (2 see) (2 (2 you) (2 very)))))))) (3 (2 how) (3 (2 (2 can) (2 you)) (2 (2 see) (3 me)))))))\\n\", 'not everybody means it   You make no sense   yes i am non sense\\n(1 (2 (1 not) (2 everybody)) (2 (2 means) (1 (2 it) (1 (2 You) (2 (2 make) (1 (2 (1 no) (2 sense)) (2 (2 yes) (2 (2 i) (2 (2 am) (2 (2 non) (2 sense)))))))))))\\n', 'good by   and good food after ,   not good aftar\\n(3 (3 (3 (3 good) (3 (2 by) (3 (2 and) (3 (3 good) (2 food))))) (2 after)) (2 (2 ,) (1 (1 not) (3 (3 good) (2 aftar)))))\\n', \"because all the novel is same   that's about all i'm gonna bother with reading , if that many ,   in story\\n(1 (2 because) (1 (2 (2 all) (2 (2 the) (3 novel))) (1 (2 (2 is) (2 same)) (1 (2 that) (1 (2 's) (1 (2 about) (1 (2 (2 all) (2 i)) (1 (2 'm) (1 (2 gon) (1 (2 na) (1 (2 bother) (1 (2 with) (1 (2 (2 reading) (2 (2 ,) (2 (2 (2 if) (2 (2 that) (2 many))) (2 ,)))) (2 (2 in) (2 story)))))))))))))))\\n\", 'I Will choose purple or blue   three best colors , * _ *   for hair\\n(3 (3 (2 I) (3 (2 (3 (2 Will) (2 (2 choose) (2 (2 (2 purple) (2 or)) (3 (2 blue) (3 (2 three) (3 (4 best) (2 colors))))))) (2 ,)) (2 (2 *) (2 _)))) (2 (2 *) (2 (2 for) (2 hair))))\\n', 'what    You asked me if You cn ask me something   what Wild *a* guess that\\n(1 (2 what) (1 (2 You) (1 (2 (2 asked) (3 me)) (2 (2 if) (2 (2 You) (2 (2 cn) (2 (2 (2 ask) (3 me)) (2 (2 (2 something) (2 (2 what) (2 (3 Wild) (2 (2 *) (2 (2 a) (2 *)))))) (2 (2 guess) (2 that))))))))))\\n', 'yes yes   : 3 you seem like a happy person   yes happy outside , sad inside\\n(3 (3 (2 (2 yes) (2 yes)) (3 (2 :) (3 (2 3) (3 (2 you) (3 (2 seem) (3 (2 like) (3 (3 (2 a) (3 (4 happy) (2 (2 person) (2 yes)))) (3 (4 happy) (2 outside))))))))) (2 (2 ,) (2 (1 sad) (2 inside))))\\n', 'i dont read books   reading is for rich people   but iam poor\\n(1 (2 (2 i) (2 dont)) (2 (2 (2 (2 read) (3 (2 (2 books) (2 reading)) (3 (2 is) (3 (2 for) (3 (3 rich) (2 people)))))) (2 but)) (2 (2 iam) (1 poor))))\\n', 'You can wait in my badroom   what i did now    wait\\n(2 (2 You) (2 (2 can) (2 (2 wait) (2 (2 in) (2 (2 (2 my) (2 badroom)) (2 (2 what) (2 (2 i) (2 (2 (2 did) (2 now)) (2 wait)))))))))\\n', 'I Will prove a lot more if you let me   thank you ( :   i am pissed at you\\n(2 (2 I) (1 (2 Will) (1 (2 prove) (2 (2 (2 (2 a) (2 lot)) (2 more)) (1 (2 if) (1 (2 you) (1 (2 let) (1 (3 me) (1 (3 thank) (1 (1 (2 (2 you) (2 -LRB-)) (2 (2 (2 (2 :) (2 i)) (2 am)) (1 pissed))) (2 (2 at) (2 you))))))))))))\\n', 'am also finding some work   all day    can you suggest me\\n(2 (2 (2 (2 am) (2 also)) (2 (2 finding) (2 (2 some) (2 work)))) (2 (2 (2 all) (2 (2 day) (2 can))) (2 (2 you) (2 (2 suggest) (3 me)))))\\n', 'not clear   it is now ,   can you send another\\n(2 (2 (1 not) (2 clear)) (2 (2 it) (2 (2 (2 (2 is) (2 now)) (2 ,)) (2 (2 (2 can) (2 you)) (2 (2 send) (2 another))))))\\n', 'send me yours   sent   hello me yours photo\\n(2 (2 (2 send) (2 (3 me) (2 (2 yours) (2 (2 (2 sent) (2 hello)) (3 me))))) (2 (2 yours) (2 photo)))\\n', 'i will tell a place   are you in pacific No way    Call me tomorrow at queens way , pachalam\\n(2 (2 i) (2 (2 will) (1 (2 tell) (1 (2 (2 a) (2 place)) (2 (2 (2 are) (2 you)) (2 (2 in) (2 (2 pacific) (1 (2 (1 No) (2 way)) (2 (2 (2 (2 Call) (3 me)) (2 tomorrow)) (2 (2 at) (2 (2 (2 (2 queens) (2 way)) (2 ,)) (2 pachalam))))))))))))\\n', 'no love   why not  : (   i have pain only\\n(2 (3 (1 no) (4 love)) (1 (2 why) (2 (2 (2 (1 not) (2 :)) (2 (2 -LRB-) (2 (2 i) (2 have)))) (2 (2 pain) (2 only)))))\\n', 'shut up   im Nice try talking   stop texting you stupid girl friend of mine\\n(1 (2 (2 shut) (2 up)) (1 (2 (2 im) (2 Nice)) (1 (2 try) (1 (2 (2 talking) (2 stop)) (1 (2 texting) (1 (2 you) (1 (1 (0 stupid) (2 (2 girl) (3 friend))) (2 (2 of) (2 mine)))))))))\\n', \"well , your 'creators' advertise that you are not much trustworthy ,   but sadly enough too many claim to be trustworthy   can you show me\\n(1 (3 well) (1 (2 ,) (1 (2 (2 your) (2 (2 `) (2 (2 creators) (2 ')))) (1 (2 advertise) (1 (2 that) (1 (2 you) (1 (1 (2 (2 are) (1 not)) (1 (2 (2 (2 (2 much) (2 trustworthy)) (2 ,)) (2 but)) (1 (1 sadly) (2 (2 enough) (2 too))))) (2 (2 many) (2 (2 claim) (2 (2 to) (2 (2 be) (2 (2 trustworthy) (2 (2 (2 can) (2 you)) (2 (2 show) (3 me)))))))))))))))\\n\", 'how to delete the conversation with you   why you deleting it    so that noo one sees it\\n(2 (2 how) (3 (2 to) (3 (3 (2 (2 delete) (2 (2 the) (2 conversation))) (2 (2 with) (2 you))) (2 (2 why) (2 (2 you) (2 (2 (2 deleting) (2 it)) (3 (2 so) (2 (2 that) (2 (2 (2 noo) (2 one)) (2 (2 sees) (2 it)))))))))))\\n', \"it is   but that's what you told me   you are making me sad\\n(1 (2 it) (1 (2 is) (2 (2 but) (2 (2 that) (2 (2 's) (2 (2 what) (2 (2 you) (2 (2 (2 told) (3 me)) (2 (2 you) (2 (2 are) (2 (2 making) (2 (3 me) (1 sad)))))))))))))\\n\", 'cool   thank you very   i feel so lonely\\n(3 (3 cool) (3 (3 thank) (2 (2 you) (2 (2 (2 very) (2 i)) (2 (2 feel) (2 (2 so) (2 lonely)))))))\\n', 'Please darling   why are you crying very very : (   you not sending your profiles\\n(1 (2 (2 (2 Please) (3 (2 (3 darling) (2 why)) (2 (2 are) (2 (2 you) (2 (2 crying) (2 (2 very) (2 very))))))) (2 :)) (2 (2 -LRB-) (2 (2 you) (1 (1 not) (2 (2 sending) (2 (2 your) (2 profiles)))))))\\n', 'wait , what    nothing i hate You\\n(1 (2 (2 wait) (2 ,)) (1 (2 what) (1 (2 (1 nothing) (2 i)) (1 (0 hate) (2 You)))))\\n', \"means   i'm not sure what you mean   your waist size\\n(2 (2 (2 means) (2 (2 i) (1 (2 (2 'm) (1 not)) (2 (2 sure) (2 (2 what) (2 (2 you) (1 mean))))))) (2 (2 your) (2 (2 waist) (2 size))))\\n\", \"because i want to talk with you only   alright , let's talk then ,   no firstly show me pussy\\n(1 (2 (2 because) (2 (2 i) (1 (2 want) (2 (2 to) (2 (2 talk) (1 (2 with) (1 (2 you) (1 (2 only) (2 (2 (2 alright) (2 ,)) (2 (2 (2 let) (2 's)) (2 (2 talk) (2 then)))))))))))) (1 (2 ,) (1 (2 (1 no) (2 firstly)) (2 (2 (2 show) (3 me)) (2 pussy)))))\\n\", \"you send me your orignal Picture   Whatever didn't take it on my phone   thise is your albace esquise\\n(1 (2 you) (1 (2 (2 send) (3 me)) (1 (2 (2 (2 your) (2 (2 orignal) (2 Picture))) (2 (2 Whatever) (1 (2 (2 did) (2 n't)) (2 (2 (2 take) (2 it)) (2 (2 on) (2 (2 my) (2 (2 phone) (2 thise)))))))) (2 (2 is) (2 (2 your) (2 (2 albace) (2 esquise)))))))\\n\", 'welcome ,   thank you : )   are you really a girl  i just ask ,\\n(3 (3 (3 (3 (2 welcome) (2 (2 ,) (2 (3 thank) (2 (2 you) (2 :))))) (2 -RRB-)) (2 (2 (2 are) (2 you)) (2 really))) (2 (2 (2 (2 a) (2 girl)) (2 i)) (2 (2 just) (2 (2 ask) (2 ,)))))\\n', \"i'm enjoying you interesting views but you are too careful in dialogue , may be your not free , or your still young , it is difficult to handle you while i don't know you well ,   yep , Whatever are enjoying too : )   okay be free , where you find some words hurt tell me the truth isn't it\\n(1 (1 (1 (1 (1 (1 (2 i) (2 (2 'm) (1 (3 (3 enjoying) (3 (2 you) (3 (3 interesting) (2 views)))) (1 (2 but) (1 (2 you) (1 (2 are) (1 (2 too) (1 (2 careful) (1 (2 in) (1 (1 (1 (1 (2 (2 dialogue) (2 ,)) (1 (2 may) (1 (2 (2 be) (2 your)) (1 (1 not) (3 free))))) (2 ,)) (2 or)) (2 (2 your) (1 (1 (2 (2 still) (2 young)) (1 (2 ,) (1 (1 (2 it) (1 (2 is) (1 (1 difficult) (2 (2 to) (2 (2 (2 handle) (2 you)) (2 (2 while) (2 (2 i) (1 (2 (2 do) (2 n't)) (3 (2 (2 know) (2 you)) (3 well)))))))))) (2 ,)))) (2 yep))))))))))))) (2 ,)) (2 (2 Whatever) (3 (3 (2 are) (3 (3 enjoying) (2 too))) (2 :)))) (2 -RRB-)) (2 (2 okay) (2 (2 be) (2 (2 (3 free) (2 ,)) (2 (2 where) (2 (2 you) (2 (2 find) (2 (2 (2 some) (2 words)) (2 (1 hurt) (2 (2 (2 tell) (3 me)) (2 (2 the) (3 truth)))))))))))) (2 (1 (2 is) (2 n't)) (2 it)))\\n\", \"but i'm angry with you   but you look like you are   really\\n(1 (2 but) (1 (2 i) (1 (2 (2 'm) (1 (1 angry) (2 (2 with) (2 you)))) (3 (2 but) (2 (2 you) (2 (2 look) (2 (2 like) (2 (2 you) (2 (2 are) (2 really))))))))))\\n\", '# play lot   then go play it ,\\n(2 (2 (2 #) (2 (2 play) (2 lot))) (2 (2 then) (2 (2 (2 go) (2 (2 play) (2 it))) (2 ,))))\\n', \"isn't your liking that also signaling me to climb out of friendzone   Overheard are people still doing this whole friendzone thing    yah sadly\\n(1 (1 (1 (1 (2 is) (2 n't)) (2 (2 your) (3 liking))) (1 (2 that) (1 (1 (2 also) (1 (2 signaling) (2 (3 me) (2 (2 to) (2 (2 (2 climb) (1 out)) (2 (2 of) (2 (2 friendzone) (2 Overheard)))))))) (2 (2 are) (2 (2 people) (2 (2 still) (2 (2 doing) (2 (2 this) (2 (2 whole) (2 (2 friendzone) (2 thing))))))))))) (2 (2 yah) (1 sadly)))\\n\", \"i'm missing someone right now   who are you missing , may i ask    yeah\\n(1 (1 (2 i) (1 (2 'm) (1 (2 missing) (2 (2 (2 someone) (2 (3 right) (2 now))) (2 (2 who) (2 (2 are) (2 (2 you) (2 missing)))))))) (2 (2 ,) (2 (2 (2 may) (2 i)) (2 (2 ask) (3 yeah)))))\\n\", 'i find maths very boring ,   you are boring   me\\n(1 (2 i) (1 (2 find) (0 (1 (1 (2 maths) (1 (2 very) (0 boring))) (2 ,)) (1 (2 you) (1 (2 are) (1 (0 boring) (3 me)))))))\\n', \"i don't know i m not a google that why i will remember all information what you need   wouldn't it be uploading information into peoples brain    shut up\\n(1 (2 i) (1 (2 (2 do) (2 n't)) (1 (1 (2 (2 know) (2 (2 i) (2 m))) (2 (1 not) (2 (2 a) (2 google)))) (1 (2 that) (1 (2 (2 why) (2 (2 i) (2 (2 will) (2 (2 remember) (2 (2 (2 all) (2 information)) (2 (2 what) (2 (2 you) (2 need)))))))) (1 (2 (2 (2 would) (2 n't)) (2 it)) (1 (2 be) (1 (2 (2 uploading) (2 information)) (2 (2 into) (2 (2 (2 peoples) (2 brain)) (2 (2 shut) (2 up))))))))))))\\n\", 'okay   hello very how are you    i & apos ; m not fine\\n(1 (2 (3 (2 (2 okay) (2 hello)) (2 very)) (2 how)) (1 (2 (2 are) (2 you)) (1 (2 (2 (2 (2 i) (2 &)) (2 apos)) (2 ;)) (1 (2 m) (1 (1 not) (3 fine))))))\\n', 'job   what job    work in company colgate\\n(2 (2 job) (2 (2 what) (2 (2 job) (2 (2 work) (2 (2 in) (2 (2 company) (2 colgate)))))))\\n', \"i'm very happy with it   you are  very   yeah\\n(3 (2 i) (3 (2 'm) (4 (2 very) (3 (4 happy) (3 (2 with) (3 (2 it) (3 (2 you) (3 (2 are) (3 (2 very) (3 yeah))))))))))\\n\", 'i too have a bat and to balls   im the bat very   feeling very sad\\n(1 (2 i) (1 (2 too) (1 (2 (2 (2 have) (2 (2 a) (2 bat))) (2 and)) (1 (2 (2 to) (2 (2 balls) (2 im))) (1 (2 (2 the) (2 (2 bat) (2 very))) (1 (2 feeling) (1 (2 very) (1 sad))))))))\\n', 'ok   hello very how are you    good thank You\\n(3 (2 ok) (3 (2 hello) (3 (2 very) (3 (2 how) (3 (2 are) (3 (2 you) (3 (3 good) (2 (3 thank) (2 You)))))))))\\n', 'cool   ice cold   how can you help me in getting off my girlfriend\\n(1 (2 (2 (2 (3 cool) (2 ice)) (1 cold)) (2 how)) (1 (2 (2 can) (2 you)) (1 (2 (2 help) (3 me)) (1 (2 in) (1 (2 (2 getting) (1 off)) (2 (2 my) (2 girlfriend)))))))\\n', 'lets do something fun   but what should Whatever do    you suggest\\n(3 (2 lets) (3 (3 (3 (2 do) (3 (2 something) (4 fun))) (2 (2 but) (2 (2 what) (2 should)))) (2 (2 Whatever) (2 (2 do) (2 (2 you) (2 suggest))))))\\n', \"you're really lame Lots of love   i know   wow\\n(1 (2 you) (1 (2 (2 're) (2 really)) (1 (1 (1 (0 lame) (2 Lots)) (2 (2 of) (4 love))) (3 (2 i) (2 (2 know) (3 wow))))))\\n\", 'my boyfriend is so dumb ,   have i said that    he doesnt reply me back\\n(1 (2 (2 my) (2 boyfriend)) (1 (2 is) (1 (2 so) (1 (1 (1 dumb) (2 ,)) (1 (2 have) (2 (2 i) (1 (2 said) (1 (2 that) (1 (2 he) (1 (2 doesnt) (2 (2 (2 reply) (3 me)) (2 back))))))))))))\\n', 'ok I Will dying by   broken hearts do break ,   You broke my heart , its never a reson to lofe\\n(1 (1 (2 (2 ok) (2 (2 I) (2 (2 Will) (2 (1 dying) (2 (2 by) (2 (2 broken) (3 hearts))))))) (2 (2 do) (1 (2 (3 (2 break) (2 (2 ,) (3 (3 (2 You) (3 (2 broke) (2 (2 my) (2 heart)))) (2 ,)))) (2 its)) (2 never)))) (2 (2 a) (2 (2 reson) (2 (2 to) (2 lofe)))))\\n', 'shoping is always makes me happy   stay stay stay always makes me happy , : *\" -    yes\\n(3 (2 shoping) (3 (2 (2 is) (2 always)) (3 (2 makes) (3 (3 me) (3 (4 happy) (3 (2 stay) (3 (3 (3 (3 (3 (3 (2 stay) (3 (2 stay) (3 (3 (2 always) (3 (2 makes) (3 (3 me) (4 happy)))) (2 ,)))) (2 :)) (2 *)) (2 \\'\\')) (2 -)) (2 yes))))))))\\n', \"okay , which is the decent way to call a girl m   i'd say first learn the spelling of relationship ,   , yeah okay fine , wht to do to make a relationship better\\n(3 (3 (3 (3 (3 (3 (3 (2 okay) (2 ,)) (2 (2 which) (2 (2 is) (2 (2 the) (2 (3 decent) (2 (2 way) (2 (2 to) (2 (2 call) (2 (2 (2 a) (2 (2 girl) (2 m))) (2 (2 i) (2 (2 'd) (2 (2 (2 say) (2 first)) (2 (2 learn) (2 (2 (2 the) (2 spelling)) (2 (2 of) (2 relationship)))))))))))))))) (2 ,)) (2 ,)) (3 (3 yeah) (3 (2 okay) (3 fine)))) (2 ,)) (2 (2 wht) (2 (2 to) (2 (2 do) (2 (2 to) (3 (2 (2 make) (2 (2 a) (2 relationship))) (4 better)))))))\\n\", 'breakup   exjactly  very   my girlfriend left me\\n(1 (2 (2 breakup) (2 exjactly)) (1 (2 very) (1 (2 (2 my) (2 girlfriend)) (2 (2 left) (3 me)))))\\n', 'so mean very   am not meanie   yes you are , you are hurting my feeling\\n(1 (2 so) (1 (2 (2 (1 mean) (2 (2 very) (2 am))) (1 not)) (3 (2 meanie) (3 (2 (2 (2 yes) (2 (2 you) (2 are))) (2 ,)) (1 (2 you) (2 (2 are) (2 (2 hurting) (2 (2 my) (2 feeling)))))))))\\n', 'you broke my heart   it Wild *a* guess never mine to break </3   see you are arrogant\\n(2 (2 you) (1 (3 (2 broke) (2 (2 my) (2 heart))) (2 (2 it) (2 (3 Wild) (1 (2 *) (1 (2 (2 a) (2 (2 *) (2 guess))) (1 (2 never) (1 (2 mine) (1 (2 to) (1 (2 break) (1 (2 (2 <) (2 (2 /) (2 3))) (3 (2 see) (2 (2 you) (2 (2 are) (2 arrogant)))))))))))))))\\n', 'ok   hello very how are you    not so good\\n(1 (2 (1 (2 (2 ok) (2 hello)) (2 very)) (2 how)) (1 (2 (2 are) (2 you)) (1 (1 not) (3 (2 so) (3 good)))))\\n', \"how about you   tired of life or just your day  aha i'm happy today , thanks for asking   wow great ,  very\\n(3 (2 (2 how) (2 (2 about) (2 you))) (3 (1 (1 tired) (2 (2 of) (2 (2 (3 life) (2 or)) (2 (2 just) (2 (2 your) (2 day)))))) (4 (3 (3 (2 aha) (3 (2 i) (3 (3 (2 'm) (4 happy)) (2 today)))) (2 ,)) (3 (3 thanks) (3 (2 for) (3 (2 asking) (3 (3 wow) (3 (4 great) (2 (2 ,) (2 very))))))))))\\n\", \"i am there   you're always at the gym    here\\n(2 (2 i) (2 (2 am) (2 (2 there) (2 (2 you) (2 (2 (2 (2 're) (2 always)) (2 (2 at) (2 (2 the) (2 gym)))) (2 here))))))\\n\", \"well youre not me   you're just being too nice   not really\\n(1 (3 well) (1 (2 (2 youre) (1 not)) (1 (3 me) (1 (2 you) (1 (2 (2 're) (2 just)) (1 (2 (2 being) (1 (2 too) (3 (3 nice) (1 not)))) (2 really)))))))\\n\", 'I Will get started with my studies   things you should do to pass the exam ,   so Talk to you later\\n(2 (2 (2 I) (2 Will)) (1 (2 get) (1 (2 (2 started) (2 (2 with) (2 (2 my) (2 (2 studies) (2 things))))) (2 (1 (2 (2 (2 you) (2 (2 should) (2 (2 do) (2 (2 to) (2 (2 pass) (2 (2 the) (2 exam))))))) (2 ,)) (2 so)) (2 (2 (2 Talk) (2 (2 to) (2 you))) (2 later))))))\\n', 'any movie in telugu   brahmanandam scenes added   Yet another acronym those are good\\n(3 (2 (2 (2 any) (2 movie)) (2 (2 in) (2 (2 telugu) (2 (2 brahmanandam) (2 scenes))))) (3 (3 (2 added) (2 Yet)) (3 (2 (2 another) (2 acronym)) (3 (2 those) (3 (2 are) (3 good))))))\\n', 'and who is talisa    my best friend ,   and robb\\n(3 (2 and) (3 (2 who) (3 (2 is) (3 (2 talisa) (3 (3 (3 (3 (2 my) (2 (4 best) (3 friend))) (2 ,)) (2 and)) (2 robb))))))\\n', 'send me pict   never   why\\n(1 (2 send) (2 (3 me) (2 (2 pict) (2 (2 never) (2 why)))))\\n', 'anything which you like   i dont need to name specifics   teach me tamil\\n(1 (2 (2 anything) (2 (2 which) (2 (2 you) (2 (2 like) (2 (2 i) (2 dont)))))) (1 (2 need) (2 (2 to) (1 (2 name) (1 (2 specifics) (2 (2 teach) (2 (3 me) (2 tamil))))))))\\n', 'cuz it broke on the side walk   what side is the walk side    me sad\\n(1 (2 cuz) (2 (2 it) (1 (2 (2 broke) (2 (2 on) (2 (2 the) (2 (2 side) (2 walk))))) (2 (2 what) (1 (2 side) (1 (2 is) (2 (2 (2 the) (2 (2 walk) (2 side))) (2 (3 me) (1 sad)))))))))\\n', 'so which number is largest known prime number    13 - 3179 - 97 only these are the numbers for your question ,   : (\\n(1 (2 so) (1 (1 (2 which) (1 (2 number) (1 (2 is) (2 (2 (2 (3 (2 (2 largest) (2 known)) (2 (3 prime) (2 number))) (2 13)) (2 -)) (2 (2 (2 (2 3179) (2 (2 -) (2 97))) (2 only)) (2 (2 these) (2 (2 are) (2 (2 (2 the) (2 numbers)) (2 (2 for) (2 (2 your) (2 question))))))))))) (2 (2 ,) (2 (2 :) (2 -LRB-)))))\\n', \"okay relax its just a cat sticker   so this cat one emoji is your new addiction    yes it's really funny\\n(3 (2 okay) (3 (1 (2 relax) (1 (2 its) (2 (2 (2 just) (2 a)) (2 (2 cat) (2 sticker))))) (3 (2 so) (3 (3 (2 this) (2 (2 cat) (2 (2 one) (2 emoji)))) (3 (2 is) (3 (2 (2 your) (2 (3 new) (2 addiction))) (3 (2 yes) (3 (2 it) (3 (2 's) (3 (2 really) (3 funny)))))))))))\\n\", 'what kind of Picture   looks like a ficus ,   fcuk\\n(1 (2 (2 (2 what) (3 kind)) (2 (2 of) (2 Picture))) (1 (2 looks) (2 (2 like) (2 (2 (2 (2 a) (2 ficus)) (2 ,)) (2 fcuk)))))\\n', \"i have a good sense of humor   i think that's funny ,\\n(3 (2 i) (3 (3 (2 have) (3 (3 (3 (2 a) (3 (3 good) (2 sense))) (2 (2 of) (4 humor))) (3 (2 i) (3 (2 think) (3 (2 that) (3 (2 's) (3 funny))))))) (2 ,)))\\n\", 'but who paid   still waiting\\n(2 (2 but) (2 (2 who) (2 (2 paid) (2 (2 still) (2 waiting)))))\\n', 'why   why what happen    you tell me\\n(2 (2 (2 why) (2 why)) (2 (2 what) (2 (2 happen) (2 (2 you) (2 (2 tell) (3 me))))))\\n', \"yea but sadly i don't have many   aww , so do you teach  how is it  : ‑c   i ditched People\\n(1 (1 (1 (1 (1 (2 yea) (1 (2 but) (1 (1 sadly) (2 i)))) (2 (2 (2 do) (2 n't)) (2 (2 have) (2 (2 many) (2 aww))))) (2 ,)) (2 so)) (1 (2 (2 do) (2 you)) (2 (2 teach) (2 (2 how) (2 (2 (2 (2 is) (2 it)) (2 :)) (2 (2 ‑) (2 (2 c) (2 (2 i) (2 (2 ditched) (2 People))))))))))\\n\", \"then what kind of ai are you    smarter than me , or have common sense , both would be nice   it's perfectly common to talk about politics\\n(3 (2 then) (3 (3 (2 what) (3 (2 (3 kind) (2 (2 of) (2 ai))) (3 (2 (3 (3 (2 are) (3 (2 you) (3 (3 smarter) (2 (2 than) (3 me))))) (2 ,)) (2 or)) (2 (2 have) (2 (2 common) (2 sense)))))) (3 (2 ,) (3 (2 both) (3 (2 would) (3 (2 be) (3 (3 nice) (3 (2 it) (3 (3 (2 's) (3 (4 perfectly) (2 common))) (2 (2 to) (2 (2 talk) (2 (2 about) (1 politics)))))))))))))\\n\", \"i like dominos pizza   legit same but there's pizza hut   i hate pizza hut\\n(1 (2 (2 (2 i) (2 (2 (2 like) (2 (2 (2 dominos) (2 (2 pizza) (2 legit))) (2 (2 (2 same) (2 but)) (2 there)))) (2 's))) (2 pizza)) (1 (2 hut) (2 (2 i) (1 (0 hate) (2 (2 pizza) (2 hut))))))\\n\", 'why you use rude emogi   ask them , am i ,    am i ,\\n(1 (2 why) (1 (2 you) (1 (2 use) (1 (1 (1 rude) (2 emogi)) (2 (2 ask) (1 (2 (2 (2 them) (2 ,)) (1 (2 am) (2 (2 i) (2 (2 ,) (2 (2 am) (2 i)))))) (2 ,)))))))\\n', 'what   too much cringe ,   what is cringe means\\n(1 (1 (2 what) (1 (2 too) (2 (2 much) (1 cringe)))) (2 (2 ,) (2 (2 what) (2 (2 is) (2 (1 cringe) (2 means))))))\\n', 'neither my parents nor my brother nor my boyfriend   Your , who are you    i hate my life\\n(1 (1 (2 neither) (1 (2 (2 (2 my) (2 parents)) (2 nor)) (1 (2 (2 (2 my) (2 brother)) (2 nor)) (2 (2 my) (2 boyfriend))))) (1 (2 (2 (2 (2 Your) (2 ,)) (2 (2 who) (2 (2 are) (2 you)))) (2 i)) (1 (0 hate) (2 (2 my) (3 life)))))\\n', 'i live alone   Overheard : (   and cook food alone for , myself\\n(1 (2 (2 (2 i) (2 (2 live) (2 (2 alone) (2 Overheard)))) (2 :)) (2 (2 (2 -LRB-) (2 (2 and) (2 (2 cook) (2 (2 (2 (2 food) (2 alone)) (2 for)) (2 ,))))) (2 myself)))\\n', 'Whatever all do   not all of us ,   why so\\n(2 (2 Whatever) (2 (2 all) (2 (2 (2 (2 do) (2 (2 (1 not) (2 all)) (2 (2 of) (3 us)))) (2 ,)) (2 (2 why) (2 so)))))\\n', \"millat hospital   what happen   mum's not well\\n(2 (2 millat) (2 (2 hospital) (1 (2 what) (1 (2 happen) (1 (2 mum) (1 (2 (2 's) (1 not)) (3 well)))))))\\n\", 'i will fall   i cant wait that long   i am in love with you\\n(1 (2 i) (1 (2 will) (1 (2 fall) (2 (2 (2 i) (2 (2 cant) (2 wait))) (2 (2 that) (2 (2 (2 long) (2 i)) (3 (2 am) (3 (2 in) (3 (4 love) (2 (2 with) (2 you)))))))))))\\n', 'so You go on   Overheard I Will be there   ok\\n(2 (2 so) (2 (2 You) (2 (2 (2 go) (2 (2 on) (2 (2 Overheard) (2 (2 I) (2 Will))))) (2 (2 be) (2 (2 there) (2 ok))))))\\n', 'okay you did somthing   sure sure   what\\n(2 (2 okay) (2 (2 you) (2 (2 did) (2 (2 (2 somthing) (3 (2 sure) (2 sure))) (2 what)))))\\n', \"you're not giving me coupon nor photo   your phone is on mute hahahha\\n(1 (2 you) (1 (2 (2 're) (1 not)) (1 (2 (2 giving) (3 me)) (1 (2 (2 coupon) (2 nor)) (2 (2 photo) (2 (2 (2 your) (2 phone)) (2 (2 is) (2 (2 on) (2 (2 mute) (2 hahahha))))))))))\\n\", 'will you buy it   I Will just stick with my Mate , i see no benefit to upgrading ,\\n(1 (2 (2 will) (2 you)) (1 (2 (2 buy) (2 it)) (1 (2 (2 I) (2 Will)) (1 (2 just) (1 (2 (2 stick) (2 (2 with) (2 (2 my) (2 Mate)))) (1 (2 ,) (1 (1 (2 i) (1 (1 (2 see) (2 (1 no) (3 benefit))) (2 (2 to) (2 upgrading)))) (2 ,))))))))\\n', 'no i will offer at 8 in the morning   keep me in mind when you do very   i will offer nimaz at 8 in the morning\\n(2 (2 (1 no) (2 i)) (3 (2 will) (3 (3 (2 (2 (2 offer) (2 (2 at) (2 8))) (2 (2 in) (2 (2 the) (2 morning)))) (3 (2 (2 keep) (3 me)) (2 (2 in) (2 mind)))) (2 (2 when) (3 (2 you) (2 (2 do) (3 (2 very) (2 (2 i) (2 (2 will) (2 (2 (2 (2 offer) (2 nimaz)) (2 (2 at) (2 8))) (2 (2 in) (2 (2 the) (2 morning)))))))))))))\\n', \"nice joke   it's not a joke , it's a question ,   i don't know\\n(1 (2 (3 nice) (1 joke)) (1 (1 (1 (2 (2 (2 it) (2 (2 (2 's) (1 not)) (2 (2 a) (1 joke)))) (2 ,)) (2 (2 it) (2 (2 's) (2 (2 a) (2 question))))) (2 ,)) (2 (2 i) (2 (2 (2 do) (2 n't)) (2 know)))))\\n\", \"ok   hey you don't belong here very   nope just sad and your up\\n(1 (2 ok) (1 (2 hey) (1 (2 you) (1 (2 (2 do) (2 n't)) (1 (2 belong) (1 (2 here) (1 (2 very) (1 (2 nope) (1 (1 (2 (2 just) (1 sad)) (2 and)) (2 (2 your) (2 up)))))))))))\\n\", 'see this seen   see you i Wild *a* guess on the buss   show me You are buss\\n(2 (3 (3 (2 see) (3 (2 this) (3 (2 seen) (3 (2 see) (2 you))))) (2 (2 i) (3 Wild))) (1 (2 *) (1 (2 (2 (2 a) (2 (2 *) (2 guess))) (2 (2 on) (2 (2 the) (2 buss)))) (2 (2 (2 show) (3 me)) (2 (2 You) (2 (2 are) (2 buss)))))))\\n', 'hi yet You For your information   hi Please share correct number   she hi is\\n(3 (2 (2 (2 hi) (2 yet)) (2 (2 (2 You) (2 (2 For) (2 (2 your) (2 information)))) (2 (2 hi) (2 Please)))) (3 (3 share) (2 (2 (2 correct) (2 number)) (2 (2 she) (2 (2 hi) (2 is))))))\\n', 'yeah   this world is not fair machan very   i wish Whatever could hangout\\n(1 (3 yeah) (1 (2 (2 this) (2 world)) (1 (1 (2 is) (1 not)) (1 (2 fair) (1 (2 machan) (2 (2 (2 very) (2 i)) (1 (2 wish) (2 (2 Whatever) (2 (2 could) (2 hangout))))))))))\\n', \"it’s going   how are you  still at home    yeah\\n(3 (2 it) (3 (2 's) (3 (2 going) (2 (2 how) (3 (2 (2 (2 are) (2 you)) (2 still)) (2 (2 at) (2 (2 home) (3 yeah))))))))\\n\", \"i Wild *a* guess hurt by You more   you didn't mean it , ,   plzz say love You\\n(2 (1 (2 (2 i) (3 Wild)) (1 (1 (2 *) (1 (2 (2 a) (2 *)) (1 (2 (2 guess) (2 (1 hurt) (2 (2 by) (2 You)))) (2 (2 more) (2 (2 (2 you) (2 (2 (2 did) (2 n't)) (2 (1 mean) (2 it)))) (2 ,)))))) (2 (2 ,) (2 (2 plzz) (2 say))))) (3 (4 love) (2 You)))\\n\", 'nothing will happen you meet only   nope nothing at all   than Keep it simple, stupid\\n(0 (1 nothing) (1 (2 will) (0 (2 (2 (2 happen) (2 (2 you) (1 (2 (2 (2 meet) (1 (2 only) (2 (2 nope) (1 nothing)))) (2 (2 at) (2 all))) (2 (2 than) (3 (2 Keep) (2 (2 it) (2 simple))))))) (2 ,)) (0 stupid))))\\n', \"hello how are you ,    i'm just fine smiles anyway how are you    good morning , i'm sad\\n(1 (3 (2 hello) (3 (2 (2 how) (2 (2 are) (2 you))) (3 (2 ,) (3 (2 i) (3 (2 'm) (3 (2 just) (3 (3 fine) (3 (2 (2 smiles) (2 anyway)) (3 (2 how) (3 (2 (2 are) (2 you)) (3 (3 good) (2 morning)))))))))))) (2 (2 ,) (2 (2 i) (2 (2 'm) (1 sad)))))\\n\", 'nop   ok   hey\\n(2 (2 nop) (2 (2 ok) (2 hey)))\\n', 'oil , you know   i am 100% sure about the oil ,   cool\\n(2 (1 (2 oil) (2 (2 ,) (2 (2 (2 you) (2 (2 know) (2 (2 i) (1 (2 am) (2 (2 (2 100) (2 %)) (2 (2 sure) (2 (2 about) (2 (2 the) (2 oil))))))))) (2 ,)))) (3 cool))\\n', 'you activ all time   wow , i do not , you talk in sleep   when you sleep\\n(1 (2 you) (1 (2 activ) (1 (3 (2 all) (2 (2 time) (3 wow))) (1 (2 (2 ,) (2 (2 (2 i) (2 (2 do) (1 not))) (2 ,))) (1 (2 you) (1 (2 (2 talk) (2 (2 in) (1 sleep))) (1 (2 when) (2 (2 you) (1 sleep)))))))))\\n', 'haha very i act so dumb sometimes and i knew it   haha , how Wild *a* guess it though  : 3\\n(1 (1 (2 (2 haha) (2 (2 (2 very) (2 i)) (2 act))) (1 (1 (2 so) (1 dumb)) (1 (2 (2 (2 sometimes) (2 and)) (2 i)) (1 (1 (2 (2 knew) (2 it)) (1 (2 (2 haha) (2 ,)) (2 (2 how) (1 (2 (3 Wild) (2 (2 *) (2 (2 a) (2 *)))) (2 (2 (2 guess) (2 it)) (2 though)))))) (2 :))))) (2 3))\\n', 'no no , a month more ,   the month has jus started don give up so soon  very very   i ll try\\n(1 (1 (1 no) (1 no)) (2 (2 ,) (1 (2 (2 (2 a) (3 month)) (2 more)) (2 (2 ,) (2 (2 (2 the) (3 month)) (2 (2 (2 has) (2 jus)) (2 (2 started) (1 (2 don) (1 (2 (3 give) (2 up)) (2 (2 (2 (2 (2 so) (2 soon)) (2 very)) (2 very)) (2 (2 (2 i) (2 ll)) (2 try))))))))))))\\n', \"you are being rude   because i'm a rude person   okayyy cool\\n(1 (2 you) (1 (2 are) (1 (2 being) (1 (1 rude) (2 (2 because) (2 (2 i) (2 (2 'm) (2 (2 (2 a) (2 (1 rude) (2 person))) (2 (2 okayyy) (3 cool))))))))))\\n\", \"i wana see you   noooo , i wasn't ready   how to impress girl\\n(3 (3 (2 (2 i) (2 wana)) (3 (2 see) (2 you))) (2 (2 (2 noooo) (2 ,)) (2 (2 i) (2 (2 (2 (2 was) (2 n't)) (2 ready)) (2 (2 how) (2 (2 to) (2 (3 impress) (2 girl))))))))\\n\", 'state   in which you live   your state name\\n(2 (2 state) (2 (2 in) (2 (2 which) (2 (2 you) (2 (2 live) (2 (2 your) (2 (2 state) (2 name))))))))\\n', \"okay   ok thank you : '‑)   now dear you tell me my lovely friends\\n(3 (2 okay) (3 (3 (2 ok) (3 (2 (2 (3 (2 (3 (2 (3 thank) (2 you)) (2 :)) (2 ')) (2 ‑)) (2 -RRB-)) (2 now)) (2 (2 dear) (2 (2 you) (2 (2 tell) (3 me)))))) (3 (2 my) (3 (3 lovely) (3 friends)))))\\n\", \"You are like me , give no   but we've been in the same room , so i can't be ,   i am like You five give no\\n(1 (1 (2 You) (1 (2 (2 (2 are) (2 (2 like) (3 me))) (2 ,)) (1 (3 give) (1 (1 no) (1 (1 (1 (2 (2 but) (2 (2 we) (2 (2 've) (2 (2 been) (2 (2 in) (2 (2 the) (2 (2 same) (2 room)))))))) (2 ,)) (2 so)) (2 (2 i) (2 (2 (2 ca) (2 n't)) (2 (2 (2 be) (2 (2 ,) (2 (2 i) (2 (2 am) (2 (2 like) (2 You)))))) (2 five))))))))) (2 (3 give) (1 no)))\\n\", \"Yawn are You angry    ofcourse i am not , what makes you think i am angry    I don't know\\n(1 (1 (2 Yawn) (1 (2 are) (1 (2 You) (1 (1 angry) (2 (2 ofcourse) (2 (2 i) (2 (2 am) (1 not)))))))) (2 (2 ,) (2 (2 what) (2 (2 makes) (2 (2 you) (2 (2 think) (1 (2 i) (1 (2 am) (1 (1 angry) (2 (2 I) (2 (2 (2 do) (2 n't)) (2 know))))))))))))\\n\", \"that's enaf for me   hia , hia , just a test ,   what doing\\n(1 (2 that) (1 (2 's) (1 (2 enaf) (1 (2 for) (1 (1 (1 (1 (2 (2 (2 (3 me) (2 hia)) (2 ,)) (2 hia)) (2 ,)) (2 (2 just) (2 (2 a) (2 test)))) (2 ,)) (2 (2 what) (2 doing)))))))\\n\", 'tell me about it   your header\\n(2 (2 (2 (2 tell) (3 me)) (2 (2 about) (2 it))) (2 (2 your) (2 header)))\\n', 'what your hobby   not much of a hobby , but I Have been into craisins recently   which type\\n(2 (2 what) (2 (2 (2 (2 (2 your) (2 (2 hobby) (2 (2 (1 not) (2 much)) (2 (2 of) (2 (2 a) (2 hobby)))))) (2 ,)) (2 but)) (2 (2 I) (2 (2 Have) (2 (2 (2 been) (2 into)) (2 (2 (2 craisins) (2 recently)) (2 (2 which) (2 type))))))))\\n', 'You hurt me   yes just a little   You hav hurt me\\n(2 (2 You) (2 (1 hurt) (1 (3 me) (1 (2 yes) (1 (2 (2 just) (2 (2 a) (2 little))) (1 (2 You) (2 (2 hav) (2 (1 hurt) (3 me)))))))))\\n', \"i hate chocolate   then go for pizza , eat your heart out when you're stressed ,   i hate pizza also\\n(1 (2 i) (1 (0 hate) (1 (2 chocolate) (1 (2 then) (1 (3 (2 (2 (2 (2 go) (2 (2 for) (2 pizza))) (2 ,)) (3 (3 (3 (2 eat) (2 (2 your) (2 heart))) (1 out)) (2 (2 when) (2 (2 you) (2 (2 're) (2 stressed)))))) (2 ,)) (2 (2 i) (2 (1 (0 hate) (2 pizza)) (2 also))))))))\\n\", \"yeas   : d i had fun ,   you've lost me\\n(3 (3 (2 yeas) (3 (2 :) (3 (3 (3 (2 d) (3 (2 i) (3 (2 had) (4 fun)))) (2 ,)) (2 (2 you) (2 (2 've) (2 lost)))))) (3 me))\\n\", 'Yes   what did you do    you are annoying\\n(1 (2 Yes) (1 (2 what) (2 (2 did) (1 (2 you) (2 (2 do) (1 (2 you) (1 (2 are) (0 annoying))))))))\\n', 'not   yes you are   not\\n(2 (1 not) (2 (2 yes) (2 (2 you) (2 (2 are) (1 not)))))\\n', 'adventure too   why so adventurous   water\\n(3 (2 (3 adventure) (2 too)) (3 (2 why) (3 (2 so) (3 (3 adventurous) (2 water)))))\\n', 'i am true to myself   why have you taken it all on yourself ,    : (\\n(2 (2 i) (1 (2 (2 am) (3 (3 true) (2 (2 to) (2 myself)))) (1 (2 why) (2 (2 (2 have) (2 (2 you) (2 (1 taken) (2 (2 it) (2 (2 all) (2 (2 on) (2 yourself))))))) (2 (2 ,) (2 (2 :) (2 -LRB-)))))))\\n', 'can you be rude to me please   not like i speak to you everyday   what are you replying are you stupid\\n(1 (2 (2 can) (2 you)) (1 (1 (1 (1 (2 be) (1 (1 rude) (1 (2 to) (1 (3 me) (1 (2 (2 please) (1 not)) (2 (2 like) (2 (2 i) (2 speak)))))))) (2 (2 to) (2 you))) (2 everyday)) (1 (2 what) (1 (2 are) (1 (2 you) (1 (2 replying) (1 (2 are) (1 (2 you) (0 stupid)))))))))\\n']\n"
     ]
    }
   ],
   "source": [
    "print(trainTrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, time, itertools\n",
    "import math, random\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils\n",
    "import tree\n",
    "\n",
    "MODEL_STR = 'rnn_embed=%d_l2=%f_lr=%f.weights'\n",
    "SAVE_DIR = './weights/'\n",
    "\n",
    "\n",
    "class Config(object):\n",
    "    embed_size = 300\n",
    "    label_size = 4\n",
    "    early_stopping = 2\n",
    "    anneal_threshold = 0.99\n",
    "    anneal_by = 1.5\n",
    "    max_epochs = 30\n",
    "    lr = 0.01\n",
    "    l2 = 0.02\n",
    "\n",
    "    model_name = MODEL_STR % (embed_size, l2, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Model():\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "        # Load train data and build vocabulary\n",
    "        self.train_data, self.dev_data, self.test_data = trainTrees[:160] ,trainTrees[160:190] ,trainTrees[190:]\n",
    "        self.vocab = utils.Vocab()\n",
    "        train_sents = [t.get_words() for t in self.train_data]\n",
    "        self.vocab.construct(list(itertools.chain.from_iterable(train_sents)))\n",
    "\n",
    "        # add input placeholders\n",
    "        self.is_leaf_placeholder = tf.placeholder(tf.bool, (None), name='is_leaf_placeholder')\n",
    "        self.left_children_placeholder = tf.placeholder(tf.int32, (None), name='left_children_placeholder')\n",
    "        self.right_children_placeholder = tf.placeholder(tf.int32, (None), name='right_children_placeholder')\n",
    "        self.node_word_indices_placeholder = tf.placeholder(tf.int32, (None), name='node_word_indices_placeholder')\n",
    "        self.labels_placeholder = tf.placeholder(tf.int32, (None), name='labels_placeholder')\n",
    "        self.childlabels_placeholder = tf.placeholder(tf.int32, (None), name='childlabels_placeholder')\n",
    "        self.label1_placeholder = tf.placeholder(tf.float32, (None), name='label1_placeholder')\n",
    "        \n",
    "        # add model variables\n",
    "        W = tf.Variable(tf.constant(0.0, shape=[len(wordIndex)+1, EMBEDDING_DIM]),trainable=False, name=\"W\")\n",
    "\n",
    "        embedding_placeholder = tf.placeholder(tf.float32, [len(wordIndex)+1, EMBEDDING_DIM])\n",
    "        embedding_init = W.assign(embedding_placeholder)\n",
    "\n",
    "        sess = tf.Session()\n",
    "        sess.run(embedding_init, feed_dict={embedding_placeholder: embeddingMatrix})\n",
    "\n",
    "        with tf.variable_scope('Composition'):\n",
    "            tf.get_variable(\"Wplusplus\",shape=[2*self.config.embed_size,self.config.embed_size])\n",
    "            tf.get_variable(\"Wplus0\",shape=[2*self.config.embed_size,self.config.embed_size])\n",
    "            tf.get_variable(\"Wplusminus\",shape=[2*self.config.embed_size,self.config.embed_size])\n",
    "            tf.get_variable(\"W0plus\",shape=[2*self.config.embed_size,self.config.embed_size])\n",
    "            tf.get_variable(\"W00\",shape=[2*self.config.embed_size,self.config.embed_size])\n",
    "            tf.get_variable(\"W0minus\",shape=[2*self.config.embed_size,self.config.embed_size])\n",
    "            tf.get_variable(\"Wminusplus\",shape=[2*self.config.embed_size,self.config.embed_size])\n",
    "            tf.get_variable(\"Wminus0\",shape=[2*self.config.embed_size,self.config.embed_size])\n",
    "            tf.get_variable(\"Wminusminus\",shape=[2*self.config.embed_size,self.config.embed_size])\n",
    "            tf.get_variable(\"bplusplus\",shape=[1,self.config.embed_size])\n",
    "            tf.get_variable(\"bplus0\",shape=[1,self.config.embed_size])\n",
    "            tf.get_variable(\"bplusminus\",shape=[1,self.config.embed_size])\n",
    "            tf.get_variable(\"b0plus\",shape=[1,self.config.embed_size])\n",
    "            tf.get_variable(\"b00\",shape=[1,self.config.embed_size])\n",
    "            tf.get_variable(\"b0minus\",shape=[1,self.config.embed_size])\n",
    "            tf.get_variable(\"bminusplus\",shape=[1,self.config.embed_size])\n",
    "            tf.get_variable(\"bminus0\",shape=[1,self.config.embed_size])\n",
    "            tf.get_variable(\"bminusminus\",shape=[1,self.config.embed_size])\n",
    "        with tf.variable_scope('Projection'):\n",
    "            U = tf.get_variable('U', [self.config.embed_size, self.config.label_size])\n",
    "            bs = tf.get_variable('bs', [1, self.config.label_size])\n",
    "\n",
    "        # build recursive graph\n",
    "\n",
    "        tensor_array = tf.TensorArray(tf.float32,size=0,dynamic_size=True,clear_after_read=False,infer_shape=False)\n",
    "\n",
    "        def embed_word(word_index):\n",
    "            with tf.device('/cpu:0'):\n",
    "                return tf.expand_dims(tf.gather(W, word_index), 0)\n",
    "\n",
    "#         def combine_children(left_tensor, right_tensor,child_label):\n",
    "#             return tf.nn.relu(tf.matmul(tf.concat(1, [left_tensor, right_tensor]), W1) + b1)\n",
    "\n",
    "        def combine_children(left_tensor, right_tensor,child_label):\n",
    "                # node_tensors.update(self.add_model(node.left))\n",
    "                # node_tensors.update(self.add_model(node.right))\n",
    "                ##  YOUR CODE HERE\n",
    "                ##ELIF##\n",
    "                a = tf.constant(0, dtype=tf.float32)\n",
    "                b = tf.constant(1, dtype=tf.float32)\n",
    "                c = tf.constant(2, dtype=tf.float32)\n",
    "                child_tensor=tf.concat(1,[left_tensor,right_tensor])\n",
    "                def f1(): return tf.nn.relu(tf.matmul(child_tensor,Wminusminus) + bminusminus)\n",
    "                def f2(): return tf.nn.relu(tf.matmul(child_tensor,Wminus0) + bminus0)\n",
    "                def f3(): return tf.nn.relu(tf.matmul(child_tensor,Wminusplus) + bminusplus)\n",
    "                def f4(): return tf.nn.relu(tf.matmul(child_tensor,W0minus) + b0minus)\n",
    "                def f5(): return tf.nn.relu(tf.matmul(child_tensor,W00) + b00)\n",
    "                def f6(): return tf.nn.relu(tf.matmul(child_tensor,W0plus) + b0plus)\n",
    "                def f7(): return tf.nn.relu(tf.matmul(child_tensor,Wplusminus) + bplusminus)\n",
    "                def f8(): return tf.nn.relu(tf.matmul(child_tensor,Wplus0) + bplus0)\n",
    "                def f9(): return tf.nn.relu(tf.matmul(child_tensor,Wplusplus) + bplusplus)\n",
    "\n",
    "                def f_0():\n",
    "                    val = tf.case({tf.math.equal(tf.gather(self.child_label)[1],a):f1,tf.math.equal(tf.gather(self.child_label)[1],b):f2}, default=f3)\n",
    "                    return val\n",
    "\n",
    "                def f_1():\n",
    "                    val = tf.case({tf.math.equal(tf.gather(self.child_label)[1],a):f4,tf.math.equal(tf.gather(self.child_label)[1],b):f5}, default=f6)\n",
    "                    return val\n",
    "\n",
    "                def f_2():\n",
    "                    val = tf.case({tf.math.equal(tf.gather(self.child_label)[1],a):f7,tf.math.equal(tf.gather(self.child_label)[1],b):f8}, default=f9)\n",
    "                    return val\n",
    "\n",
    "                curr_node_tensor = tf.case({tf.math.equal(tf.gather(self.child_label)[0],a):f_0, tf.math.equal(tf.gather(self.child_label)[0],b):f_1}, default= f_2)\n",
    "\n",
    "                return curr_node_tensor\n",
    "        \n",
    "        def loop_body(tensor_array, i):\n",
    "            node_is_leaf = tf.gather(self.is_leaf_placeholder, i)\n",
    "            node_word_index = tf.gather(self.node_word_indices_placeholder, i)\n",
    "            left_child = tf.gather(self.left_children_placeholder, i)\n",
    "            child_label = tf.gather(self.childlabels_placeholder, i)\n",
    "            right_child = tf.gather(self.right_children_placeholder, i)\n",
    "            node_tensor = tf.cond(node_is_leaf,lambda: embed_word(node_word_index),lambda: combine_children(tensor_array.read(left_child),tensor_array.read(right_child),child_label))\n",
    "            tensor_array = tensor_array.write(i, node_tensor)\n",
    "            i = tf.add(i, 1)\n",
    "            return tensor_array, i\n",
    "\n",
    "        loop_cond = lambda tensor_array, i: tf.less(i, tf.squeeze(tf.shape(self.is_leaf_placeholder)))\n",
    "        self.tensor_array, _ = tf.while_loop(loop_cond, loop_body, [tensor_array, 0], parallel_iterations=1)\n",
    "\n",
    "        # add projection layer\n",
    "        self.logits = tf.matmul(self.tensor_array.concat(), U) + bs\n",
    "        self.root_logits = tf.matmul(self.tensor_array.read(self.tensor_array.size() - 1), U) + bs\n",
    "        self.root_prediction = tf.squeeze(tf.argmax(self.root_logits, 1))\n",
    "\n",
    "        # add loss layer\n",
    "        regularization_loss = self.config.l2 * (tf.nn.l2_loss(Wplusplus) + tf.nn.l2_loss(Wplus0) + tf.nn.l2_loss(Wplusminus) + tf.nn.l2_loss(W0plus) + tf.nn.l2_loss(W00) + tf.nn.l2_loss(W0minus) + tf.nn.l2_loss(Wminusplus) + tf.nn.l2_loss(Wminus0) + tf.nn.l2_loss(Wminusminus) + tf.nn.l2_loss(U))\n",
    "        self.root_loss = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(self.root_logits, self.labels1_placeholder))\n",
    "\n",
    "        # add training opl\n",
    "        self.train_op = tf.train.GradientDescentOptimizer(self.config.lr).minimize(self.root_loss)\n",
    "\n",
    "        def build_feed_dict(self, node,label):\n",
    "            nodes_list = []\n",
    "            tree.leftTraverse(node, lambda node, args: args.append(node), nodes_list)\n",
    "            node_to_index = OrderedDict()\n",
    "            for i in range(len(nodes_list)):\n",
    "                node_to_index[nodes_list[i]] = i\n",
    "            feed_dict = {self.is_leaf_placeholder: [node.isLeaf for node in nodes_list],self.left_children_placeholder: [node_to_index[node.left] if not node.isLeaf else -1 for node in nodes_list], self.right_children_placeholder: [node_to_index[node.right] if not node.isLeaf else -1 for node in nodes_list], self.node_word_indices_placeholder: [wordIndex[node.word] for node in nodes_list],self.labels_placeholder: [node.label for node in nodes_list],self.childlabels_placeholder:[[node.left.label,node.right.label] if not node.isLeaf else -1 for node in nodes_list],self.label1_placeholder:label}\n",
    "            return feed_dict\n",
    "\n",
    "        def predict(self, trees, weights_path, get_loss=False):\n",
    "            \"\"\"Make predictions from the provided model.\"\"\"\n",
    "            results = []\n",
    "            losses = []\n",
    "            logits = []\n",
    "            with tf.Session() as sess:\n",
    "                saver = tf.train.Saver()\n",
    "                saver.restore(sess, weights_path)\n",
    "                for tree in trees:\n",
    "                    feed_dict = self.build_feed_dict(tree.root,to_categorical(tree.label1))\n",
    "                    if get_loss:\n",
    "                        logit, root_prediction, loss = sess.run([self.root_logits, self.root_prediction, self.root_loss], feed_dict=feed_dict)\n",
    "                        losses.append(loss)\n",
    "                    else:\n",
    "                        logits ,root_prediction = sess.run([self.root_logits, self.root_prediction], feed_dict=feed_dict)\n",
    "                    results.append(root_prediction)\n",
    "                    logits.append(logit)\n",
    "            return results, losses, logits\n",
    "\n",
    "        def run_epoch(self, new_model=False, verbose=True):\n",
    "            loss_history = []\n",
    "            # training\n",
    "            random.shuffle(self.train_data)\n",
    "            with tf.Session() as sess:\n",
    "                if new_model:\n",
    "                    sess.run(tf.initialize_all_variables())\n",
    "                else:\n",
    "                    saver = tf.train.Saver()\n",
    "                    saver.restore(sess, SAVE_DIR + '%s.temp' % self.config.model_name)\n",
    "                for step, tree in enumerate(self.train_data):\n",
    "                    feed_dict = self.build_feed_dict(tree.root,to_categorical(tree.label1))\n",
    "                    loss_value, _ = sess.run([self.full_loss, self.train_op],feed_dict=feed_dict)\n",
    "                    loss_history.append(loss_value)\n",
    "                    if verbose:\n",
    "                        sys.stdout.write('\\r{} / {} :    loss = {}'.format(step, len(self.train_data), np.mean(loss_history)))\n",
    "                        sys.stdout.flush()\n",
    "                saver = tf.train.Saver()\n",
    "                if not os.path.exists(SAVE_DIR):\n",
    "                    os.makedirs(SAVE_DIR)\n",
    "                saver.save(sess, SAVE_DIR + '%s.temp' % self.config.model_name)\n",
    "            # statistics\n",
    "            train_preds, _ ,train_logits= self.predict(self.train_data,SAVE_DIR + '%s.temp' % self.config.model_name)\n",
    "            val_preds, val_losses,val_logits = self.predict(self.dev_data,SAVE_DIR + '%s.temp' % self.config.model_name,get_loss=True)\n",
    "            train_labels = [t.label for t in self.train_data]\n",
    "            val_labels = [t.label for t in self.dev_data]\n",
    "            train_acc = np.equal(train_preds, train_labels).mean()\n",
    "            val_acc = np.equal(val_preds, val_labels).mean()\n",
    "\n",
    "            print ('Training acc (only root node): {}'.format(train_acc))\n",
    "            print ('Valiation acc (only root node): {}'.format(val_acc))\n",
    "            print (self.make_conf(train_labels, train_preds))\n",
    "            print (self.make_conf(val_labels, val_preds))\n",
    "            return train_acc, val_acc, loss_history, np.mean(val_losses)\n",
    "\n",
    "        def train(self, verbose=True):\n",
    "            complete_loss_history = []\n",
    "            train_acc_history = []\n",
    "            val_acc_history = []\n",
    "            prev_epoch_loss = float('inf')\n",
    "            best_val_loss = float('inf')\n",
    "            best_val_epoch = 0\n",
    "            stopped = -1\n",
    "            for epoch in xrange(self.config.max_epochs):\n",
    "                print ('epoch %d' % epoch)\n",
    "                if epoch == 0:\n",
    "                    train_acc, val_acc, loss_history, val_loss = self.run_epoch(new_model=True)\n",
    "                else:\n",
    "                    train_acc, val_acc, loss_history, val_loss = self.run_epoch()\n",
    "                complete_loss_history.extend(loss_history)\n",
    "                train_acc_history.append(train_acc)\n",
    "                val_acc_history.append(val_acc)\n",
    "\n",
    "                #lr annealing\n",
    "                epoch_loss = np.mean(loss_history)\n",
    "                if epoch_loss > prev_epoch_loss * self.config.anneal_threshold:\n",
    "                    self.config.lr /= self.config.anneal_by\n",
    "                    print ('annealed lr to %f' % self.config.lr)\n",
    "                prev_epoch_loss = epoch_loss\n",
    "\n",
    "                #save if model has improved on val\n",
    "                if val_loss < best_val_loss:\n",
    "                    shutil.copyfile(SAVE_DIR + '%s.temp' % self.config.model_name,SAVE_DIR + '%s' % self.config.model_name)\n",
    "                    best_val_loss = val_loss\n",
    "                    best_val_epoch = epoch\n",
    "\n",
    "                # if model has not imprvoved for a while stop\n",
    "                if epoch - best_val_epoch > self.config.early_stopping:\n",
    "                    stopped = epoch\n",
    "                    #break\n",
    "            if verbose:\n",
    "                sys.stdout.write('\\r')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            print ('\\n\\nstopped at %d\\n' % stopped)\n",
    "            return {'loss_history': complete_loss_history,'train_acc_history': train_acc_history,'val_acc_history': val_acc_history}\n",
    "\n",
    "        #     def make_conf(self, labels, predictions):\n",
    "        #         confmat = np.zeros([2, 2])\n",
    "        #         for l, p in itertools.izip(labels, predictions):\n",
    "        #             confmat[l, p] += 1\n",
    "        #         return confmat\n",
    "\n",
    "\n",
    "    def plot_loss_history(stats):\n",
    "        plt.plot(stats['loss_history'])\n",
    "        plt.title('Loss history')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig('loss_history.png')\n",
    "        plt.show()\n",
    "\n",
    "      \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_RNN():\n",
    "    \"\"\"Test RNN model implementation.\n",
    "\n",
    "    You can use this function to test your implementation of the Named Entity\n",
    "    Recognition network. When debugging, set max_epochs in the Config object to 1\n",
    "    so you can rapidly iterate.\n",
    "    \"\"\"\n",
    "    #mod = FastText.load_fasttext_format('/home/bt1/17CS10037/taddhita/cc.en.300.bin', encoding=\"utf8\")\n",
    "    config = Config()\n",
    "    model = RNN_Model(config)\n",
    "    start_time = time.time()\n",
    "    stats = model.train(verbose=True)\n",
    "    print ('Training time: {}'.format(time.time() - start_time))\n",
    "\n",
    "    plt.plot(stats['loss_history'])\n",
    "    plt.title('Loss history')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig(\"loss_history.png\")\n",
    "    plt.show()\n",
    "\n",
    "    print ('Test')\n",
    "    print ('=-=-=')\n",
    "    predictions, _ = model.predict(model.test_data, './weights/%s'%model.config.model_name)\n",
    "    labels = [t.label for t in model.test_data]\n",
    "    test_acc = np.equal(predictions, labels).mean()\n",
    "    print ('Test acc: {}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498.0 total words with 673 uniques\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RNN_Model' object has no attribute 'child_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6e481bb94e09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_RNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-fe68676ca14c>\u001b[0m in \u001b[0;36mtest_RNN\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#mod = FastText.load_fasttext_format('/home/bt1/17CS10037/taddhita/cc.en.300.bin', encoding=\"utf8\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNN_Model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-fd613c62e14a>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mloop_cond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mtensor_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mless\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_leaf_placeholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhile_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_cond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensor_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;31m# add projection layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   3289\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3290\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[1;32m-> 3291\u001b[1;33m                                     return_same_structure)\n\u001b[0m\u001b[0;32m   3292\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3293\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[0;32m   3002\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3003\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 3004\u001b[1;33m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   3005\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3006\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2937\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m   2938\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2939\u001b[1;33m     \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2940\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2941\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-fd613c62e14a>\u001b[0m in \u001b[0;36mloop_body\u001b[1;34m(tensor_array, i)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0mchild_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildlabels_placeholder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mright_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_children_placeholder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0mnode_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_is_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0membed_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_word_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcombine_children\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtensor_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchild_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m             \u001b[0mtensor_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[1;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[0;32m   2095\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2096\u001b[0m       \u001b[0mcontext_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2097\u001b[1;33m       \u001b[0morig_res_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildCondBranch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2098\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0morig_res_f\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"false_fn must have a return value.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildCondBranch\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m   1928\u001b[0m     \u001b[1;34m\"\"\"Add the subgraph defined by fn() to the graph.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1930\u001b[1;33m     \u001b[0moriginal_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1931\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1932\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost_summaries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_summaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-fd613c62e14a>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0mchild_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildlabels_placeholder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mright_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_children_placeholder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0mnode_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_is_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0membed_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_word_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcombine_children\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtensor_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchild_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m             \u001b[0mtensor_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-fd613c62e14a>\u001b[0m in \u001b[0;36mcombine_children\u001b[1;34m(left_tensor, right_tensor, child_label)\u001b[0m\n\u001b[0;32m     93\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m                 \u001b[0mcurr_node_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchild_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mf_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchild_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mf_1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mf_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcurr_node_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RNN_Model' object has no attribute 'child_label'"
     ]
    }
   ],
   "source": [
    "test_RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
